# éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿè¯¦ç»†æ–‡æ¡£

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºPythonçš„æ•°æ®åˆ†æå·¥å…·ï¼Œä¸“é—¨ç”¨äºä»Amazonç”µå­äº§å“è¯„è®ºä¸­æå–ã€åˆ†æå’Œå¯è§†åŒ–ä¸éŸ³é¢‘è®¾å¤‡ç›¸å…³çš„ç”¨æˆ·è¯„ä»·ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«ä¸éŸ³é¢‘è®¾å¤‡ç›¸å…³çš„è¯„è®ºï¼Œå¹¶ä»è¯„è®ºæ–‡æœ¬ä¸­æå–å…³äºéŸ³è´¨ã€èˆ’é€‚åº¦ã€ç”µæ± å¯¿å‘½ç­‰10ä¸ªå…³é”®æ–¹é¢çš„è¯„åˆ†å’Œæƒ…æ„Ÿå€¾å‘ï¼Œæœ€ç»ˆé€šè¿‡å¤šç§å¯è§†åŒ–å›¾è¡¨ç›´è§‚å±•ç¤ºåˆ†æç»“æœã€‚

### ğŸ” æ ¸å¿ƒåŠŸèƒ½

- **æ™ºèƒ½è¯„è®ºç­›é€‰**ï¼šä»ç”µå­äº§å“è¯„è®ºæ•°æ®é›†ä¸­è‡ªåŠ¨ç­›é€‰å‡ºéŸ³é¢‘è®¾å¤‡ç›¸å…³è¯„è®º
- **å¤šç»´åº¦è¯„åˆ†æå–**ï¼šåŸºäºNLPæŠ€æœ¯ä»è¯„è®ºæ–‡æœ¬ä¸­æå–10ä¸ªå…³é”®æ–¹é¢çš„è¯„åˆ†
- **å“ç‰Œä¸ä»·æ ¼åŒºé—´æ¯”è¾ƒ**ï¼šå¯¹ä¸åŒå“ç‰Œå’Œä»·æ ¼åŒºé—´äº§å“åœ¨å„æ–¹é¢çš„è¡¨ç°è¿›è¡Œæ¯”è¾ƒåˆ†æ
- **æƒ…æ„Ÿåˆ†æ**ï¼šåˆ†æç”¨æˆ·å¯¹å„ä¸ªæ–¹é¢çš„æƒ…æ„Ÿå€¾å‘
- **ç›´è§‚æ•°æ®å¯è§†åŒ–**ï¼šé€šè¿‡é›·è¾¾å›¾ã€çƒ­åŠ›å›¾ã€æ¡å½¢å›¾ç­‰å¤šç§æ–¹å¼å±•ç¤ºåˆ†æç»“æœ
- **PowerBIå¯¼å‡ºæ”¯æŒ**ï¼šæ”¯æŒå¯¼å‡ºå¤„ç†åçš„æ•°æ®ç”¨äºPowerBIåˆ›å»ºé«˜çº§å¯è§†åŒ–å’ŒæŠ¥è¡¨

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š

```
audio_review_analysis/
â”œâ”€â”€ data/                      # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ raw/                   # åŸå§‹æ•°æ®
â”‚   â””â”€â”€ processed/             # å¤„ç†åçš„æ•°æ®
â”œâ”€â”€ outputs/                   # è¾“å‡ºæ–‡ä»¶
â”‚   â””â”€â”€ figures/               # ç”Ÿæˆçš„å¯è§†åŒ–
â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ data/                  # æ•°æ®è·å–ä¸é¢„å¤„ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ acquisition.py     # æ•°æ®è·å–æ¨¡å—
â”‚   â”‚   â””â”€â”€ preprocessing.py   # æ•°æ®é¢„å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ features/              # ç‰¹å¾å·¥ç¨‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ aspect_extraction.py # æ–¹é¢æå–ä¸åˆ†æ
â”‚   â””â”€â”€ visualization/         # å¯è§†åŒ–æ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ plots.py           # ç»˜å›¾åŠŸèƒ½
â”œâ”€â”€ config.py                  # å…¨å±€é…ç½®æ–‡ä»¶
â”œâ”€â”€ main.py                    # ä¸»ç¨‹åºå…¥å£
â””â”€â”€ requirements.txt           # é¡¹ç›®ä¾èµ–
```

### ğŸ“Š æ•°æ®æµç¨‹

1. **æ•°æ®è·å–**ï¼šä»Amazonä¸‹è½½ç”µå­äº§å“è¯„è®ºæ•°æ®
2. **æ•°æ®é¢„å¤„ç†**ï¼šæ¸…æ´—æ–‡æœ¬ã€åˆ†è¯ã€æå–åŸºæœ¬ç‰¹å¾
3. **æ–¹é¢æå–**ï¼šè¯†åˆ«è¯„è®ºä¸­ä¸å„ä¸ªæ–¹é¢ç›¸å…³çš„å¥å­å¹¶è¿›è¡Œæƒ…æ„Ÿåˆ†æ
4. **è¯„åˆ†ç”Ÿæˆ**ï¼šä¸ºæ¯ä¸ªæ–¹é¢ç”Ÿæˆæ ‡å‡†åŒ–è¯„åˆ†
5. **æ•°æ®å¯è§†åŒ–**ï¼šåˆ›å»ºå¤šç§å›¾è¡¨å±•ç¤ºåˆ†æç»“æœ

## ğŸ› ï¸ å®‰è£…ä¸è®¾ç½®

### ç¯å¢ƒè¦æ±‚

- Python 3.6+
- pip åŒ…ç®¡ç†å™¨

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“ï¼ˆæˆ–åˆ›å»ºé¡¹ç›®ç›®å½•ï¼‰**

```bash
mkdir audio_review_analysis
cd audio_review_analysis
```

2. **åˆ›å»ºç›®å½•ç»“æ„**

```bash
mkdir -p data/raw data/processed outputs/figures
mkdir -p src/data src/features src/visualization
```

3. **å®‰è£…ä¾èµ–**

```bash
pip install pandas numpy matplotlib seaborn plotly nltk spacy scikit-learn wordcloud tqdm requests openpyxl
python -m nltk.downloader punkt vader_lexicon stopwords
python -m spacy download en_core_web_sm
```

## ğŸ“ è¯¦ç»†ç»„ä»¶è¯´æ˜

# å®Œæ•´éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿä»£ç 

ä»¥ä¸‹æ˜¯é¡¹ç›®çš„å®Œæ•´ä»£ç ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ¨¡å—å’Œæ–°æ·»åŠ çš„Streamlitä»ªè¡¨ç›˜ã€‚

## config.py

```python
"""
é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«é¡¹ç›®çš„å…¨å±€é…ç½®
"""

# æ•°æ®ç›¸å…³é…ç½®
DATA_CONFIG = {
    'amazon_url': "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz",
    'raw_data_dir': 'data/raw',
    'processed_data_dir': 'data/processed',
    'sample_size': None  # è®¾ç½®ä¸ºæ•´æ•°ä»¥é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡ï¼Œç”¨äºæµ‹è¯•
}

# éŸ³é¢‘è®¾å¤‡å…³é”®è¯
AUDIO_KEYWORDS = [
    'headphone', 'earphone', 'earbud', 'headset', 
    'earpiece', 'airpod', 'speaker', 'soundbar',
    'audio', 'sound', 'bluetooth speaker', 'wireless headphone'
]

# æ–¹é¢åˆ†æé…ç½®
ASPECT_CONFIG = {
    'sound_quality': ['sound', 'audio', 'quality', 'clarity', 'bass', 'treble', 'mid', 'tone', 'frequency'],
    'comfort': ['comfort', 'comfortable', 'fit', 'ear', 'cushion', 'padding', 'weight', 'light', 'heavy'],
    'battery': ['battery', 'charge', 'life', 'duration', 'hour', 'lasting', 'power'],
    'connectivity': ['bluetooth', 'connection', 'pair', 'wireless', 'range', 'distance', 'stable'],
    'noise_cancellation': ['noise', 'cancellation', 'anc', 'isolation', 'ambient', 'background'],
    'build_quality': ['build', 'quality', 'material', 'durable', 'sturdy', 'plastic', 'metal', 'robust'],
    'controls': ['control', 'button', 'touch', 'volume', 'skip', 'pause', 'play', 'responsive'],
    'price': ['price', 'cost', 'value', 'worth', 'expensive', 'cheap', 'affordable'],
    'microphone': ['mic', 'microphone', 'call', 'voice', 'speak', 'talking'],
    'design': ['design', 'look', 'style', 'color', 'appearance', 'aesthetic']
}

# å¯è§†åŒ–é…ç½®
VIZ_CONFIG = {
    'output_dir': 'outputs/figures',
    'color_scheme': 'viridis',
    'min_reviews_per_brand': 30,
    'min_reviews_per_price_range': 10
}
```

## src/data/acquisition.py

```python
import os
import gzip
import json
import requests
import pandas as pd
from tqdm import tqdm

def download_amazon_dataset(url, target_path):
    """
    ä¸‹è½½Amazonè¯„è®ºæ•°æ®é›†
    
    Args:
        url (str): æ•°æ®é›†URL
        target_path (str): ä¿å­˜è·¯å¾„
    
    Returns:
        str: æ•°æ®é›†ä¿å­˜çš„æœ¬åœ°è·¯å¾„
    """
    # åˆ›å»ºç›®å½•
    os.makedirs(os.path.dirname(target_path), exist_ok=True)
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
    if os.path.exists(target_path):
        print(f"æ–‡ä»¶å·²å­˜åœ¨: {target_path}")
        return target_path
    
    # ä¸‹è½½æ•°æ®
    print(f"æ­£åœ¨ä» {url} ä¸‹è½½æ•°æ®...")
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(target_path, 'wb') as f, tqdm(
        desc=target_path,
        total=total_size,
        unit='iB',
        unit_scale=True,
        unit_divisor=1024,
    ) as bar:
        for data in response.iter_content(chunk_size=1024):
            size = f.write(data)
            bar.update(size)
    
    print(f"ä¸‹è½½å®Œæˆã€‚æ–‡ä»¶å·²ä¿å­˜è‡³ {target_path}")
    return target_path

def load_amazon_dataset(file_path):
    """
    åŠ è½½å¹¶è§£æAmazonè¯„è®ºæ•°æ®é›†
    
    Args:
        file_path (str): æ•°æ®é›†æ–‡ä»¶è·¯å¾„(.json.gz)
    
    Returns:
        pd.DataFrame: åŒ…å«è¯„è®ºæ•°æ®çš„DataFrame
    """
    print(f"æ­£åœ¨ä» {file_path} åŠ è½½æ•°æ®...")
    data = []
    with gzip.open(file_path, 'rt', encoding='utf-8') as f:
        for i, line in enumerate(tqdm(f)):
            data.append(json.loads(line.strip()))
            # æµ‹è¯•æ—¶å¯ä»¥é™åˆ¶åŠ è½½æ•°é‡
            # if i > 100000:  # åŠ è½½å‰10ä¸‡æ¡æ•°æ®
            #     break
    
    df = pd.DataFrame(data)
    print(f"å·²åŠ è½½ {len(df)} æ¡è¯„è®º")
    return df

def filter_audio_products(df, keywords=None):
    """
    ä»ç”µå­äº§å“è¯„è®ºä¸­ç­›é€‰éŸ³é¢‘è®¾å¤‡ç›¸å…³è¯„è®º
    
    Args:
        df (pd.DataFrame): ç”µå­äº§å“è¯„è®ºDataFrame
        keywords (list, optional): éŸ³é¢‘è®¾å¤‡å…³é”®è¯åˆ—è¡¨
    
    Returns:
        pd.DataFrame: éŸ³é¢‘è®¾å¤‡ç›¸å…³è¯„è®º
    """
    if keywords is None:
        keywords = [
            'headphone', 'earphone', 'earbud', 'headset', 
            'earpiece', 'airpod', 'speaker', 'soundbar',
            'audio', 'sound', 'bluetooth speaker', 'wireless headphone'
        ]
    
    # åœ¨äº§å“åç§°æˆ–è¯„è®ºä¸­åŒ¹é…å…³é”®è¯
    keyword_pattern = '|'.join(keywords)
    
    # æ£€æŸ¥è¯„è®ºæ ‡é¢˜
    title_mask = df['summary'].str.contains(
        keyword_pattern, case=False, na=False
    )
    
    # æ£€æŸ¥è¯„è®ºå†…å®¹
    text_mask = df['reviewText'].str.contains(
        keyword_pattern, case=False, na=False
    )
    
    # åˆå¹¶ç­›é€‰æ¡ä»¶
    filtered_df = df[title_mask | text_mask].copy()
    
    print(f"æ‰¾åˆ° {len(filtered_df)} æ¡éŸ³é¢‘è®¾å¤‡ç›¸å…³è¯„è®º")
    return filtered_df

def get_audio_dataset(url=None, save_dir='data/raw', processed_dir='data/processed'):
    """
    è·å–å¹¶å¤„ç†éŸ³é¢‘è®¾å¤‡è¯„è®ºæ•°æ®é›†
    
    Args:
        url (str, optional): æ•°æ®é›†URL
        save_dir (str): åŸå§‹æ•°æ®ä¿å­˜ç›®å½•
        processed_dir (str): å¤„ç†åæ•°æ®ä¿å­˜ç›®å½•
    
    Returns:
        pd.DataFrame: å¤„ç†åçš„éŸ³é¢‘è®¾å¤‡è¯„è®ºæ•°æ®
    """
    # é»˜è®¤ä½¿ç”¨Amazonç”µå­äº§å“è¯„è®ºæ•°æ®é›†
    if url is None:
        url = "http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz"
    
    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    filename = url.split('/')[-1]
    raw_path = os.path.join(save_dir, filename)
    processed_path = os.path.join(processed_dir, 'audio_reviews.csv')
    
    # å¦‚æœå·²ç»å¤„ç†è¿‡ï¼Œç›´æ¥åŠ è½½
    if os.path.exists(processed_path):
        print(f"æ­£åœ¨ä» {processed_path} åŠ è½½å·²å¤„ç†çš„æ•°æ®")
        return pd.read_csv(processed_path)
    
    # ä¸‹è½½æ•°æ®
    download_amazon_dataset(url, raw_path)
    
    # åŠ è½½æ•°æ®
    df = load_amazon_dataset(raw_path)
    
    # ç­›é€‰éŸ³é¢‘è®¾å¤‡ç›¸å…³è¯„è®º
    audio_df = filter_audio_products(df)
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    os.makedirs(os.path.dirname(processed_path), exist_ok=True)
    audio_df.to_csv(processed_path, index=False)
    print(f"å·²å°†å¤„ç†åçš„æ•°æ®ä¿å­˜è‡³ {processed_path}")
    
    return audio_df
```

## src/data/preprocessing.py

```python
import pandas as pd
import numpy as np
import re
import datetime
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk

# ç¡®ä¿ä¸‹è½½å¿…è¦çš„NLTKèµ„æº
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('punkt')
    nltk.download('stopwords')

def clean_text(text):
    """
    æ¸…æ´—æ–‡æœ¬æ•°æ®
    
    Args:
        text (str): åŸå§‹æ–‡æœ¬
    
    Returns:
        str: æ¸…æ´—åçš„æ–‡æœ¬
    """
    if pd.isna(text) or not isinstance(text, str):
        return ""
    
    # è½¬ä¸ºå°å†™
    text = text.lower()
    
    # ç§»é™¤URL
    text = re.sub(r'http\S+', '', text)
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™æ ‡ç‚¹
    text = re.sub(r'[^\w\s\.\,\!\?\-\']', ' ', text)
    
    # æ›¿æ¢å¤šä¸ªç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def tokenize_text(text, remove_stopwords=True):
    """
    åˆ†è¯å¹¶å¯é€‰åœ°ç§»é™¤åœç”¨è¯
    
    Args:
        text (str): æ–‡æœ¬
        remove_stopwords (bool): æ˜¯å¦ç§»é™¤åœç”¨è¯
    
    Returns:
        list: åˆ†è¯åˆ—è¡¨
    """
    if not text:
        return []
    
    # åˆ†è¯
    tokens = word_tokenize(text)
    
    # ç§»é™¤åœç”¨è¯
    if remove_stopwords:
        stop_words = set(stopwords.words('english'))
        tokens = [t for t in tokens if t.lower() not in stop_words]
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œæ•°å­—
    tokens = [t for t in tokens if t.isalpha()]
    
    return tokens

def preprocess_reviews(df):
    """
    é¢„å¤„ç†è¯„è®ºæ•°æ®
    
    Args:
        df (pd.DataFrame): åŸå§‹è¯„è®ºæ•°æ®
    
    Returns:
        pd.DataFrame: é¢„å¤„ç†åçš„æ•°æ®
    """
    print("å¼€å§‹é¢„å¤„ç†...")
    processed_df = df.copy()
    
    # é‡å‘½ååˆ—ä»¥ä¾¿æ›´ç›´è§‚
    column_mapping = {
        'reviewerID': 'user_id',
        'asin': 'product_id',
        'reviewerName': 'user_name',
        'helpful': 'helpful_votes',
        'reviewText': 'review_text',
        'overall': 'rating',
        'summary': 'review_title',
        'unixReviewTime': 'review_timestamp',
        'reviewTime': 'review_date'
    }
    
    # åº”ç”¨åªæœ‰åœ¨æ•°æ®é›†ä¸­å­˜åœ¨çš„åˆ—çš„æ˜ å°„
    valid_mapping = {k: v for k, v in column_mapping.items() if k in processed_df.columns}
    processed_df = processed_df.rename(columns=valid_mapping)
    
    # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
    required_columns = ['review_text', 'rating']
    missing_columns = [col for col in required_columns if col not in processed_df.columns]
    if missing_columns:
        raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
    
    # æ¸…æ´—æ–‡æœ¬
    print("æ¸…æ´—æ–‡æœ¬...")
    processed_df['clean_review_text'] = processed_df['review_text'].apply(clean_text)
    
    if 'review_title' in processed_df.columns:
        processed_df['clean_review_title'] = processed_df['review_title'].apply(clean_text)
    
    # åˆ†è¯
    print("åˆ†è¯å¤„ç†...")
    processed_df['tokens'] = processed_df['clean_review_text'].apply(tokenize_text)
    
    # è®¡ç®—è¯„è®ºé•¿åº¦
    processed_df['review_length'] = processed_df['clean_review_text'].str.len()
    processed_df['word_count'] = processed_df['tokens'].apply(len)
    
    # å¤„ç†æ—¶é—´æˆ³
    if 'review_timestamp' in processed_df.columns:
        processed_df['review_date'] = pd.to_datetime(processed_df['review_timestamp'], unit='s')
        processed_df['review_year'] = processed_df['review_date'].dt.year
        processed_df['review_month'] = processed_df['review_date'].dt.month
    
    # å¤„ç†helpful_voteså­—æ®µ
    if 'helpful_votes' in processed_df.columns and isinstance(processed_df['helpful_votes'].iloc[0], list):
        processed_df['helpful_count'] = processed_df['helpful_votes'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 0)
        processed_df['total_votes'] = processed_df['helpful_votes'].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else 0)
    
    # æ·»åŠ éªŒè¯æ ‡è®°
    processed_df['verified_purchase'] = False  # é»˜è®¤è®¾ä¸ºFalseï¼Œå®é™…æ•°æ®ä¸­å¯èƒ½æœ‰æ­¤å­—æ®µ
    
    print("é¢„å¤„ç†å®Œæˆã€‚")
    return processed_df

def create_price_categories(df, product_meta=None):
    """
    åˆ›å»ºä»·æ ¼åŒºé—´åˆ†ç±»
    
    Args:
        df (pd.DataFrame): é¢„å¤„ç†åçš„è¯„è®ºæ•°æ®
        product_meta (pd.DataFrame, optional): äº§å“å…ƒæ•°æ®ï¼ŒåŒ…å«ä»·æ ¼ä¿¡æ¯
    
    Returns:
        pd.DataFrame: æ·»åŠ ä»·æ ¼åŒºé—´çš„æ•°æ®
    """
    result_df = df.copy()
    
    if product_meta is not None and 'price' in product_meta.columns:
        # å¦‚æœæœ‰äº§å“å…ƒæ•°æ®ï¼Œä½¿ç”¨å®é™…ä»·æ ¼
        product_prices = product_meta[['asin', 'price']].rename(columns={'asin': 'product_id'})
        result_df = result_df.merge(product_prices, on='product_id', how='left')
        
        # å®šä¹‰ä»·æ ¼åŒºé—´
        conditions = [
            (result_df['price'] < 50),
            (result_df['price'] >= 50) & (result_df['price'] < 150),
            (result_df['price'] >= 150) & (result_df['price'] < 300),
            (result_df['price'] >= 300)
        ]
        choices = ['é¢„ç®—å‹(<$50)', 'ä¸­ç«¯($50-$150)', 
                   'é«˜ç«¯($150-$300)', 'è±ªåå‹(>$300)']
        
        result_df['price_range'] = np.select(conditions, choices, default='æœªçŸ¥')
    else:
        # å¦‚æœæ²¡æœ‰äº§å“å…ƒæ•°æ®ï¼Œä½¿ç”¨äº§å“IDçš„å“ˆå¸Œå€¼æ¨¡æ‹Ÿ
        import hashlib
        
        def assign_price_range(product_id):
            # ä½¿ç”¨äº§å“IDçš„å“ˆå¸Œå€¼æ¨¡æ‹Ÿä»·æ ¼åˆ†å¸ƒ
            hash_value = int(hashlib.md5(str(product_id).encode()).hexdigest(), 16) % 4
            ranges = ['é¢„ç®—å‹(<$50)', 'ä¸­ç«¯($50-$150)', 
                      'é«˜ç«¯($150-$300)', 'è±ªåå‹(>$300)']
            return ranges[hash_value]
        
        result_df['price_range'] = result_df['product_id'].apply(assign_price_range)
    
    return result_df

def assign_brand_categories(df, brand_mapping=None):
    """
    åˆ†é…å“ç‰Œç±»åˆ«
    
    Args:
        df (pd.DataFrame): è¯„è®ºæ•°æ®
        brand_mapping (dict, optional): äº§å“IDåˆ°å“ç‰Œçš„æ˜ å°„
    
    Returns:
        pd.DataFrame: æ·»åŠ å“ç‰Œä¿¡æ¯çš„æ•°æ®
    """
    result_df = df.copy()
    
    if brand_mapping is not None:
        # å¦‚æœæœ‰å“ç‰Œæ˜ å°„ï¼Œç›´æ¥ä½¿ç”¨
        result_df['brand'] = result_df['product_id'].map(brand_mapping)
    else:
        # ä»è¯„è®ºæ–‡æœ¬ä¸­è¯†åˆ«å¸¸è§å“ç‰Œ
        common_brands = [
            'sony', 'bose', 'sennheiser', 'apple', 'beats', 'samsung', 
            'jabra', 'jbl', 'audio-technica', 'skullcandy', 'anker', 
            'soundcore', 'shure', 'akg', 'jaybird', 'plantronics', 'mpow'
        ]
        
        def extract_brand(text):
            if not isinstance(text, str):
                return 'unknown'
            
            text_lower = text.lower()
            for brand in common_brands:
                if brand in text_lower:
                    return brand
            return 'other'
        
        # ä»è¯„è®ºæ ‡é¢˜å’Œæ­£æ–‡ä¸­æå–å“ç‰Œ
        result_df['brand'] = result_df.apply(
            lambda row: extract_brand(str(row.get('clean_review_title', '')) + ' ' + str(row.get('clean_review_text', ''))), 
            axis=1
        )
    
    return result_df

def get_processed_dataset(raw_df=None, save_path='data/processed/processed_audio_reviews.csv'):
    """
    è·å–å®Œæ•´é¢„å¤„ç†çš„æ•°æ®é›†
    
    Args:
        raw_df (pd.DataFrame, optional): åŸå§‹æ•°æ®
        save_path (str): å¤„ç†åæ•°æ®ä¿å­˜è·¯å¾„
    
    Returns:
        pd.DataFrame: å®Œæ•´é¢„å¤„ç†çš„æ•°æ®é›†
    """
    # å¦‚æœä¿å­˜è·¯å¾„å­˜åœ¨ï¼Œç›´æ¥åŠ è½½
    try:
        processed_df = pd.read_csv(save_path)
        print(f"ä» {save_path} åŠ è½½å·²å¤„ç†çš„æ•°æ®é›†")
        return processed_df
    except FileNotFoundError:
        pass
    
    if raw_df is None:
        raise ValueError("æœªæä¾›åŸå§‹æ•°æ®ä¸”æœªæ‰¾åˆ°å·²å¤„ç†æ•°æ®ã€‚")
    
    # æ‰§è¡Œé¢„å¤„ç†
    df = preprocess_reviews(raw_df)
    
    # åˆ›å»ºä»·æ ¼åŒºé—´
    df = create_price_categories(df)
    
    # åˆ†é…å“ç‰Œ
    df = assign_brand_categories(df)
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    import os
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    df.to_csv(save_path, index=False)
    print(f"å·²å°†å¤„ç†åçš„æ•°æ®é›†ä¿å­˜è‡³ {save_path}")
    
    return df
```

## src/features/aspect_extraction.py

```python
import pandas as pd
import numpy as np
import spacy
from collections import defaultdict
import re
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk

# ç¡®ä¿ä¸‹è½½å¿…è¦çš„NLTKèµ„æº
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    nltk.download('vader_lexicon')

# åŠ è½½spaCyæ¨¡å‹
try:
    nlp = spacy.load('en_core_web_sm')
except OSError:
    print("æ­£åœ¨ä¸‹è½½spaCyæ¨¡å‹...")
    spacy.cli.download("en_core_web_sm")
    nlp = spacy.load('en_core_web_sm')

# åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
sid = SentimentIntensityAnalyzer()

# å®šä¹‰éŸ³é¢‘è®¾å¤‡ç›¸å…³çš„æ–¹é¢åŠå…³é”®è¯
AUDIO_ASPECTS = {
    'sound_quality': ['sound', 'audio', 'quality', 'clarity', 'bass', 'treble', 'mid', 'tone', 'frequency'],
    'comfort': ['comfort', 'comfortable', 'fit', 'ear', 'cushion', 'padding', 'weight', 'light', 'heavy'],
    'battery': ['battery', 'charge', 'life', 'duration', 'hour', 'lasting', 'power'],
    'connectivity': ['bluetooth', 'connection', 'pair', 'wireless', 'range', 'distance', 'stable'],
    'noise_cancellation': ['noise', 'cancellation', 'anc', 'isolation', 'ambient', 'background'],
    'build_quality': ['build', 'quality', 'material', 'durable', 'sturdy', 'plastic', 'metal', 'robust'],
    'controls': ['control', 'button', 'touch', 'volume', 'skip', 'pause', 'play', 'responsive'],
    'price': ['price', 'cost', 'value', 'worth', 'expensive', 'cheap', 'affordable'],
    'microphone': ['mic', 'microphone', 'call', 'voice', 'speak', 'talking'],
    'design': ['design', 'look', 'style', 'color', 'appearance', 'aesthetic']
}

def extract_aspect_sentences(text, aspects_dict=AUDIO_ASPECTS):
    """
    ä»è¯„è®ºæ–‡æœ¬ä¸­æå–ä¸å„æ–¹é¢ç›¸å…³çš„å¥å­
    
    Args:
        text (str): è¯„è®ºæ–‡æœ¬
        aspects_dict (dict): æ–¹é¢åŠå¯¹åº”å…³é”®è¯å­—å…¸
    
    Returns:
        dict: å„æ–¹é¢åŠå¯¹åº”çš„å¥å­
    """
    if not isinstance(text, str) or not text:
        return {}
    
    # åˆ†å¥
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    # å­˜å‚¨å„æ–¹é¢çš„å¥å­
    aspect_sentences = defaultdict(list)
    
    # éå†å¥å­ï¼ŒåŒ¹é…æ–¹é¢
    for sentence in sentences:
        sentence = sentence.lower()
        for aspect, keywords in aspects_dict.items():
            if any(keyword in sentence for keyword in keywords):
                aspect_sentences[aspect].append(sentence)
    
    return dict(aspect_sentences)

def analyze_aspect_sentiment(aspect_sentences):
    """
    åˆ†æå„æ–¹é¢çš„æƒ…æ„Ÿå¾—åˆ†
    
    Args:
        aspect_sentences (dict): å„æ–¹é¢åŠå¯¹åº”çš„å¥å­
    
    Returns:
        dict: å„æ–¹é¢çš„æƒ…æ„Ÿå¾—åˆ†
    """
    aspect_sentiments = {}
    
    for aspect, sentences in aspect_sentences.items():
        if not sentences:
            continue
        
        # è®¡ç®—æ¯ä¸ªå¥å­çš„æƒ…æ„Ÿå¾—åˆ†
        sentiment_scores = [sid.polarity_scores(sentence)['compound'] for sentence in sentences]
        
        # è®¡ç®—å¹³å‡æƒ…æ„Ÿå¾—åˆ†
        aspect_sentiments[aspect] = {
            'score': np.mean(sentiment_scores),
            'sentence_count': len(sentences),
            'sentences': sentences,
            'positive_example': sentences[np.argmax(sentiment_scores)] if sentiment_scores else "",
            'negative_example': sentences[np.argmin(sentiment_scores)] if sentiment_scores else ""
        }
    
    return aspect_sentiments

def extract_aspects_batch(reviews_df, text_column='clean_review_text', max_samples=None):
    """
    æ‰¹é‡æå–è¯„è®ºä¸­çš„æ–¹é¢åŠæƒ…æ„Ÿ
    
    Args:
        reviews_df (pd.DataFrame): è¯„è®ºæ•°æ®
        text_column (str): æ–‡æœ¬åˆ—å
        max_samples (int, optional): æœ€å¤§å¤„ç†æ ·æœ¬æ•°
    
    Returns:
        pd.DataFrame: åŒ…å«æ–¹é¢åˆ†æç»“æœçš„æ•°æ®
    """
    print("æ­£åœ¨ä»è¯„è®ºä¸­æå–æ–¹é¢...")
    result_df = reviews_df.copy()
    
    # é™åˆ¶å¤„ç†æ ·æœ¬æ•°
    if max_samples and len(result_df) > max_samples:
        result_df = result_df.sample(max_samples, random_state=42)
    
    # åˆ›å»ºç”¨äºå­˜å‚¨ç»“æœçš„åˆ—
    result_df['aspect_sentences'] = None
    result_df['aspect_sentiments'] = None
    
    # é€æ¡å¤„ç†è¯„è®º
    aspect_sentences_list = []
    aspect_sentiments_list = []
    
    for idx, row in result_df.iterrows():
        text = row[text_column]
        
        # æå–æ–¹é¢å¥å­
        aspect_sentences = extract_aspect_sentences(text)
        aspect_sentences_list.append(aspect_sentences)
        
        # åˆ†ææ–¹é¢æƒ…æ„Ÿ
        aspect_sentiments = analyze_aspect_sentiment(aspect_sentences)
        aspect_sentiments_list.append(aspect_sentiments)
    
    # æ·»åŠ åˆ°DataFrame
    result_df['aspect_sentences'] = aspect_sentences_list
    result_df['aspect_sentiments'] = aspect_sentiments_list
    
    print("æ–¹é¢æå–å®Œæˆã€‚")
    return result_df

def generate_aspect_scores(reviews_with_aspects):
    """
    ç”Ÿæˆå„æ–¹é¢çš„è¯„åˆ†
    
    Args:
        reviews_with_aspects (pd.DataFrame): å¸¦æœ‰æ–¹é¢åˆ†æçš„è¯„è®ºæ•°æ®
    
    Returns:
        pd.DataFrame: æ–¹é¢è¯„åˆ†æ•°æ®
    """
    print("æ­£åœ¨ç”Ÿæˆæ–¹é¢è¯„åˆ†...")
    # è·å–æ‰€æœ‰æ–¹é¢
    all_aspects = list(AUDIO_ASPECTS.keys())
    
    # åˆ›å»ºç”¨äºå­˜å‚¨ç»“æœçš„DataFrame
    result_df = reviews_with_aspects.copy()
    
    # ä¸ºæ¯ä¸ªæ–¹é¢åˆ›å»ºå¾—åˆ†åˆ—
    for aspect in all_aspects:
        result_df[f'{aspect}_score'] = None
        result_df[f'{aspect}_count'] = 0
    
    # è®¡ç®—æ–¹é¢å¾—åˆ†
    for idx, row in result_df.iterrows():
        aspect_sentiments = row['aspect_sentiments']
        if not aspect_sentiments:
            continue
            
        for aspect, data in aspect_sentiments.items():
            result_df.at[idx, f'{aspect}_score'] = data['score']
            result_df.at[idx, f'{aspect}_count'] = data['sentence_count']
    
    # å°†å¾—åˆ†è§„èŒƒåŒ–åˆ°1-10èŒƒå›´
    for aspect in all_aspects:
        score_col = f'{aspect}_score'
        # å°†-1åˆ°1çš„å¾—åˆ†æ˜ å°„åˆ°1-10
        mask = result_df[score_col].notna()
        result_df.loc[mask, score_col] = ((result_df.loc[mask, score_col] + 1) / 2) * 9 + 1
    
    print("æ–¹é¢è¯„åˆ†å®Œæˆã€‚")
    return result_df

def create_review_aspects_dataset(df, output_path='data/processed/review_aspects.csv'):
    """
    åˆ›å»ºå¸¦æœ‰æ–¹é¢åˆ†æçš„å®Œæ•´æ•°æ®é›†
    
    Args:
        df (pd.DataFrame): é¢„å¤„ç†åçš„è¯„è®ºæ•°æ®
        output_path (str): è¾“å‡ºè·¯å¾„
    
    Returns:
        pd.DataFrame: åŒ…å«æ–¹é¢åˆ†æçš„æ•°æ®é›†
    """
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å¤„ç†å¥½çš„æ•°æ®
    try:
        result_df = pd.read_csv(output_path)
        print(f"ä» {output_path} åŠ è½½æ–¹é¢åˆ†æç»“æœ")
        return result_df
    except FileNotFoundError:
        pass
    
    # æå–æ–¹é¢ä¿¡æ¯
    df_with_aspects = extract_aspects_batch(df)
    
    # ç”Ÿæˆæ–¹é¢è¯„åˆ†
    result_df = generate_aspect_scores(df_with_aspects)
    
    # ä¿å­˜ç»“æœ
    import os
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # å°†å­—å…¸åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿ä¿å­˜
    result_df['aspect_sentences'] = result_df['aspect_sentences'].apply(lambda x: str(x) if x else None)
    result_df['aspect_sentiments'] = result_df['aspect_sentiments'].apply(lambda x: str(x) if x else None)
    
    # ä¿å­˜
    result_df.to_csv(output_path, index=False)
    print(f"å·²å°†æ–¹é¢åˆ†æç»“æœä¿å­˜è‡³ {output_path}")
    
    return result_df
```

## src/visualization/plots.py

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from wordcloud import WordCloud
import os

# è®¾ç½®ç»˜å›¾æ ·å¼
plt.style.use('ggplot')
sns.set(style="whitegrid")

def plot_rating_distribution(df, output_dir='outputs/figures'):
    """
    ç»˜åˆ¶è¯„åˆ†åˆ†å¸ƒå›¾
    
    Args:
        df (pd.DataFrame): è¯„è®ºæ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        None
    """
    print("ç»˜åˆ¶è¯„åˆ†åˆ†å¸ƒ...")
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¡ç®—è¯„åˆ†åˆ†å¸ƒ
    rating_counts = df['rating'].value_counts().sort_index()
    
    # åˆ›å»ºç»˜å›¾
    plt.figure(figsize=(10, 6))
    sns.barplot(x=rating_counts.index, y=rating_counts.values)
    plt.title('è¯„åˆ†åˆ†å¸ƒ')
    plt.xlabel('è¯„åˆ†')
    plt.ylabel('æ•°é‡')
    
    # ä¿å­˜å›¾åƒ
    plt.savefig(os.path.join(output_dir, 'rating_distribution.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # ä½¿ç”¨Plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨
    fig = px.bar(
        x=rating_counts.index, 
        y=rating_counts.values,
        labels={'x': 'è¯„åˆ†', 'y': 'æ•°é‡'},
        title='è¯„åˆ†åˆ†å¸ƒ',
        color=rating_counts.index,
        color_continuous_scale='Viridis'
    )
    
    fig.write_html(os.path.join(output_dir, 'rating_distribution.html'))
    
    print(f"è¯„åˆ†åˆ†å¸ƒå›¾å·²ä¿å­˜è‡³ {output_dir}")

def plot_aspect_scores(df, output_dir='outputs/figures'):
    """
    ç»˜åˆ¶å„æ–¹é¢è¯„åˆ†çš„é›·è¾¾å›¾
    
    Args:
        df (pd.DataFrame): åŒ…å«æ–¹é¢è¯„åˆ†çš„æ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        None
    """
    print("ç»˜åˆ¶æ–¹é¢è¯„åˆ†...")
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è¯†åˆ«æ–¹é¢è¯„åˆ†åˆ—
    aspect_cols = [col for col in df.columns if col.endswith('_score')]
    if not aspect_cols:
        print("æœªæ‰¾åˆ°æ–¹é¢è¯„åˆ†åˆ—ã€‚")
        return
    
    # è®¡ç®—æ¯ä¸ªæ–¹é¢çš„å¹³å‡å¾—åˆ†
    aspect_means = {}
    for col in aspect_cols:
        aspect = col.replace('_score', '')
        aspect_means[aspect] = df[col].mean()
    
    # æ’åºå¹¶æ•´ç†æ•°æ®
    aspect_means = {k: v for k, v in sorted(aspect_means.items(), key=lambda item: item[1], reverse=True)}
    
    # ç¿»è¯‘æ–¹é¢åç§°ä¸ºä¸­æ–‡
    aspect_translation = {
        'sound_quality': 'éŸ³è´¨',
        'comfort': 'èˆ’é€‚åº¦',
        'battery': 'ç”µæ± ',
        'connectivity': 'è¿æ¥æ€§',
        'noise_cancellation': 'é™å™ª',
        'build_quality': 'åšå·¥',
        'controls': 'æ§åˆ¶',
        'price': 'ä»·æ ¼',
        'microphone': 'éº¦å…‹é£',
        'design': 'è®¾è®¡'
    }
    
    # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
    categories = [aspect_translation.get(k, k) for k in aspect_means.keys()]
    values = list(aspect_means.values())
    
    # ç¡®ä¿æ²¡æœ‰NaNå€¼
    values = [0 if np.isnan(v) else v for v in values]
    
    # åˆ›å»ºé›·è¾¾å›¾
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        name='å¹³å‡åˆ†æ•°'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 10]
            )
        ),
        title="éŸ³é¢‘è®¾å¤‡å„æ–¹é¢è¯„åˆ†"
    )
    
    fig.write_html(os.path.join(output_dir, 'aspect_scores_radar.html'))
    
    # åˆ›å»ºæ¡å½¢å›¾
    plt.figure(figsize=(12, 8))
    bars = plt.barh([aspect_translation.get(k, k) for k in aspect_means.keys()], list(aspect_means.values()))
    
    # è®¾ç½®é¢œè‰²æ¸å˜
    for i, bar in enumerate(bars):
        bar.set_color(plt.cm.viridis(i / len(bars)))
    
    plt.title('å„æ–¹é¢å¹³å‡è¯„åˆ†')
    plt.xlabel('å¹³å‡åˆ†æ•° (1-10)')
    plt.xlim(0, 10)
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, v in enumerate(aspect_means.values()):
        plt.text(v + 0.1, i, f"{v:.2f}", va='center')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'aspect_scores_bar.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"æ–¹é¢è¯„åˆ†å›¾å·²ä¿å­˜è‡³ {output_dir}")

def plot_price_range_comparison(df, output_dir='outputs/figures'):
    """
    æ¯”è¾ƒä¸åŒä»·æ ¼åŒºé—´äº§å“çš„æ–¹é¢è¯„åˆ†
    
    Args:
        df (pd.DataFrame): åŒ…å«æ–¹é¢è¯„åˆ†å’Œä»·æ ¼åŒºé—´çš„æ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        None
    """
    print("ç»˜åˆ¶ä»·æ ¼åŒºé—´æ¯”è¾ƒ...")
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    if 'price_range' not in df.columns:
        print("æœªæ‰¾åˆ°price_rangeåˆ—ã€‚")
        return
    
    # è¯†åˆ«æ–¹é¢è¯„åˆ†åˆ—
    aspect_cols = [col for col in df.columns if col.endswith('_score')]
    if not aspect_cols:
        print("æœªæ‰¾åˆ°æ–¹é¢è¯„åˆ†åˆ—ã€‚")
        return
    
    # ç¿»è¯‘æ–¹é¢åç§°ä¸ºä¸­æ–‡
    aspect_translation = {
        'sound_quality': 'éŸ³è´¨',
        'comfort': 'èˆ’é€‚åº¦',
        'battery': 'ç”µæ± ',
        'connectivity': 'è¿æ¥æ€§',
        'noise_cancellation': 'é™å™ª',
        'build_quality': 'åšå·¥',
        'controls': 'æ§åˆ¶',
        'price': 'ä»·æ ¼',
        'microphone': 'éº¦å…‹é£',
        'design': 'è®¾è®¡'
    }
    
    # ä¸ºæ¯ä¸ªä»·æ ¼åŒºé—´è®¡ç®—å¹³å‡æ–¹é¢è¯„åˆ†
    price_ranges = df['price_range'].unique()
    
    # åˆ›å»ºå¤šå­å›¾
    fig = make_subplots(
        rows=1, cols=1,
        subplot_titles=['ä¸åŒä»·æ ¼åŒºé—´çš„æ–¹é¢è¯„åˆ†']
    )
    
    # ä¸ºæ¯ä¸ªä»·æ ¼åŒºé—´æ·»åŠ ä¸€æ¡æŠ˜çº¿
    for price_range in price_ranges:
        price_df = df[df['price_range'] == price_range]
        
        if len(price_df) < 10:  # è·³è¿‡æ ·æœ¬å¤ªå°‘çš„ä»·æ ¼åŒºé—´
            continue
            
        # è®¡ç®—è¿™ä¸ªä»·æ ¼åŒºé—´çš„æ–¹é¢å¹³å‡åˆ†
        aspect_means = {}
        for col in aspect_cols:
            aspect = col.replace('_score', '')
            aspect_means[aspect] = price_df[col].mean()
        
        # æ’åº
        aspect_means = {k: v for k, v in sorted(aspect_means.items(), key=lambda item: item[0])}
        
        # æ·»åŠ æŠ˜çº¿
        fig.add_trace(
            go.Scatter(
                x=[aspect_translation.get(k, k) for k in aspect_means.keys()],
                y=list(aspect_means.values()),
                mode='lines+markers',
                name=price_range
            ),
            row=1, col=1
        )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title="ä¸åŒä»·æ ¼åŒºé—´çš„æ–¹é¢è¯„åˆ†",
        xaxis_title="æ–¹é¢",
        yaxis_title="å¹³å‡åˆ†æ•° (1-10)",
        legend_title="ä»·æ ¼åŒºé—´",
        yaxis=dict(range=[0, 10])
    )
    
    fig.write_html(os.path.join(output_dir, 'price_range_comparison.html'))
    
    print(f"ä»·æ ¼åŒºé—´æ¯”è¾ƒå›¾å·²ä¿å­˜è‡³ {output_dir}")

def plot_brand_comparison(df, output_dir='outputs/figures', min_reviews=30):
    """
    æ¯”è¾ƒä¸åŒå“ç‰Œäº§å“çš„æ–¹é¢è¯„åˆ†
    
    Args:
        df (pd.DataFrame): åŒ…å«æ–¹é¢è¯„åˆ†å’Œå“ç‰Œçš„æ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
        min_reviews (int): æœ€å°‘è¯„è®ºæ•°é‡çš„é˜ˆå€¼
    
    Returns:
        None
    """
    print("ç»˜åˆ¶å“ç‰Œæ¯”è¾ƒ...")
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    if 'brand' not in df.columns:
        print("æœªæ‰¾åˆ°brandåˆ—ã€‚")
        return
    
    # è¯†åˆ«æ–¹é¢è¯„åˆ†åˆ—
    aspect_cols = [col for col in df.columns if col.endswith('_score')]
    if not aspect_cols:
        print("æœªæ‰¾åˆ°æ–¹é¢è¯„åˆ†åˆ—ã€‚")
        return
    
    # ç¿»è¯‘æ–¹é¢åç§°ä¸ºä¸­æ–‡
    aspect_translation = {
        'sound_quality': 'éŸ³è´¨',
        'comfort': 'èˆ’é€‚åº¦',
        'battery': 'ç”µæ± ',
        'connectivity': 'è¿æ¥æ€§',
        'noise_cancellation': 'é™å™ª',
        'build_quality': 'åšå·¥',
        'controls': 'æ§åˆ¶',
        'price': 'ä»·æ ¼',
        'microphone': 'éº¦å…‹é£',
        'design': 'è®¾è®¡'
    }
    
    # è®¡ç®—æ¯ä¸ªå“ç‰Œçš„è¯„è®ºæ•°
    brand_counts = df['brand'].value_counts()
    
    # åªä¿ç•™æœ‰è¶³å¤Ÿè¯„è®ºçš„å“ç‰Œ
    valid_brands = brand_counts[brand_counts >= min_reviews].index.tolist()
    
    if not valid_brands:
        print(f"æ²¡æœ‰å“ç‰Œçš„è¯„è®ºæ•°é‡è‡³å°‘ä¸º {min_reviews}ã€‚")
        return
    
    # å°†å“ç‰Œé™åˆ¶åœ¨å‰10ä¸ª
    valid_brands = valid_brands[:10]
    
    # ä¸ºæ¯ä¸ªå“ç‰Œè®¡ç®—å¹³å‡æ–¹é¢è¯„åˆ†
    brand_data = []
    
    for brand in valid_brands:
        brand_df = df[df['brand'] == brand]
        
        # è®¡ç®—è¿™ä¸ªå“ç‰Œçš„æ–¹é¢å¹³å‡åˆ†
        aspect_means = {}
        for col in aspect_cols:
            aspect = col.replace('_score', '')
            aspect_means[aspect] = brand_df[col].mean()
        
        # æ·»åŠ åˆ°åˆ—è¡¨
        for aspect, score in aspect_means.items():
            brand_data.append({
                'Brand': brand,
                'Aspect': aspect_translation.get(aspect, aspect),
                'Score': score
            })
    
    # åˆ›å»ºæ•°æ®æ¡†
    brand_scores_df = pd.DataFrame(brand_data)
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    plt.figure(figsize=(14, 10))
    heatmap_data = brand_scores_df.pivot(index='Brand', columns='Aspect', values='Score')
    sns.heatmap(heatmap_data, annot=True, cmap='viridis', vmin=1, vmax=10, fmt='.2f')
    plt.title('å“ç‰Œæ–¹é¢è¯„åˆ†æ¯”è¾ƒ')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'brand_comparison_heatmap.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # åˆ›å»ºäº¤äº’å¼çƒ­åŠ›å›¾
    fig = px.imshow(
        heatmap_data,
        labels=dict(x="æ–¹é¢", y="å“ç‰Œ", color="åˆ†æ•°"),
        x=heatmap_data.columns,
        y=heatmap_data.index,
        aspect="auto",
        color_continuous_scale='Viridis',
        range_color=[1, 10],
        title='å“ç‰Œæ–¹é¢è¯„åˆ†æ¯”è¾ƒ'
    )
    
    fig.update_layout(
        xaxis_title="æ–¹é¢",
        yaxis_title="å“ç‰Œ"
    )
    
    fig.write_html(os.path.join(output_dir, 'brand_comparison_heatmap.html'))
    
    print(f"å“ç‰Œæ¯”è¾ƒå›¾å·²ä¿å­˜è‡³ {output_dir}")

def plot_word_clouds(df, output_dir='outputs/figures'):
    """
    ä¸ºé«˜è¯„åˆ†å’Œä½è¯„åˆ†è¯„è®ºåˆ›å»ºè¯äº‘
    
    Args:
        df (pd.DataFrame): è¯„è®ºæ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        None
    """
    print("åˆ›å»ºè¯äº‘...")
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ†ç¦»é«˜è¯„åˆ†å’Œä½è¯„åˆ†è¯„è®º
    high_rated = df[df['rating'] >= 4]['clean_review_text'].dropna()
    low_rated = df[df['rating'] <= 2]['clean_review_text'].dropna()
    
    if len(high_rated) == 0 or len(low_rated) == 0:
        print("æ•°æ®ä¸è¶³ä»¥åˆ›å»ºè¯äº‘ã€‚")
        return
    
    # åˆå¹¶æ–‡æœ¬
    high_text = ' '.join(high_rated)
    low_text = ' '.join(low_rated)
    
    # åˆ›å»ºé«˜è¯„åˆ†è¯äº‘
    plt.figure(figsize=(12, 8))
    wordcloud = WordCloud(
        width=800, height=400,
        background_color='white',
        max_words=200,
        colormap='viridis',
        contour_width=1,
        contour_color='steelblue'
    ).generate(high_text)
    
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('é«˜è¯„åˆ†è¯„è®ºè¯äº‘ (4-5æ˜Ÿ)')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'high_rated_wordcloud.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # åˆ›å»ºä½è¯„åˆ†è¯äº‘
    plt.figure(figsize=(12, 8))
    wordcloud = WordCloud(
        width=800, height=400,
        background_color='white',
        max_words=200,
        colormap='inferno',
        contour_width=1,
        contour_color='firebrick'
    ).generate(low_text)
    
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('ä½è¯„åˆ†è¯„è®ºè¯äº‘ (1-2æ˜Ÿ)')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'low_rated_wordcloud.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"è¯äº‘å·²ä¿å­˜è‡³ {output_dir}")

def create_all_visualizations(df, output_dir='outputs/figures'):
    """
    åˆ›å»ºæ‰€æœ‰å¯è§†åŒ–
    
    Args:
        df (pd.DataFrame): å¸¦æœ‰æ–¹é¢åˆ†æçš„è¯„è®ºæ•°æ®
        output_dir (str): è¾“å‡ºç›®å½•
    
    Returns:
        None
    """
    plot_rating_distribution(df, output_dir)
    plot_aspect_scores(df, output_dir)
    plot_price_range_comparison(df, output_dir)
    plot_brand_comparison(df, output_dir)
    plot_word_clouds(df, output_dir)
    
    print("æ‰€æœ‰å¯è§†åŒ–å·²åˆ›å»ºå®Œæˆã€‚")
```

## src/utils/export.py

```python
import os
import pandas as pd
import numpy as np
import re
from datetime import datetime

def clean_for_excel(df):
    """
    æ¸…ç†DataFrameä¸­çš„éæ³•Excelå­—ç¬¦
    
    Args:
        df (pd.DataFrame): åŸå§‹æ•°æ®æ¡†
        
    Returns:
        pd.DataFrame: æ¸…ç†åçš„æ•°æ®æ¡†
    """
    # å¤åˆ¶DataFrameé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    cleaned_df = df.copy()
    
    # å®šä¹‰Excelä¸æ”¯æŒçš„å­—ç¬¦çš„æ­£åˆ™è¡¨è¾¾å¼
    illegal_chars_regex = r'[\000-\010]|[\013-\014]|[\016-\037]'
    
    # å¯¹æ¯ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„åˆ—è¿›è¡Œæ¸…ç†
    for col in cleaned_df.columns:
        if cleaned_df[col].dtype == 'object':
            # å¯¹å­—ç¬¦ä¸²ç±»å‹çš„åˆ—åº”ç”¨æ›¿æ¢
            cleaned_df[col] = cleaned_df[col].astype(str).apply(
                lambda x: re.sub(illegal_chars_regex, '', x) if pd.notnull(x) else x
            )
            
            # å¤„ç†å…¶ä»–ç‰¹æ®Šå­—ç¬¦
            cleaned_df[col] = cleaned_df[col].apply(
                lambda x: re.sub(r'[\x00-\x1f\x7f-\x9f]', '', str(x)) if pd.notnull(x) else x
            )
    
    return cleaned_df

def prepare_powerbi_data(df, output_path='outputs/powerbi_data'):
    """
    ä¸º PowerBI å‡†å¤‡æ•°æ®æ–‡ä»¶
    
    Args:
        df (pd.DataFrame): å¸¦æœ‰æ–¹é¢åˆ†æçš„è¯„è®ºæ•°æ®
        output_path (str): è¾“å‡ºç›®å½•è·¯å¾„
    
    Returns:
        dict: åŒ…å«å„ä¸ªæ•°æ®æ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    print("æ­£åœ¨å‡†å¤‡ PowerBI æ•°æ®...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_path, exist_ok=True)
    
    # è·å–æ–¹é¢è¯„åˆ†åˆ—
    aspect_cols = [col for col in df.columns if col.endswith('_score')]
    aspects = [col.replace('_score', '') for col in aspect_cols]
    
    # 1. ä¸»æ•°æ®è¡¨ - è¿™å°†æ˜¯æˆ‘ä»¬çš„äº‹å®è¡¨
    main_data = df.copy()
    
    # å°†æ–¹é¢è¯„åˆ†æ•°æ®è½¬æ¢ä¸ºé•¿æ ¼å¼ï¼Œæ›´é€‚åˆPowerBIå¤„ç†
    aspect_data_list = []
    
    for _, row in df.iterrows():
        review_id = row.get('review_id', '') or row.get('user_id', '') or ''
        product_id = row.get('product_id', '')
        rating = row.get('rating', 0)
        brand = row.get('brand', 'unknown')
        price_range = row.get('price_range', 'unknown')
        review_date = row.get('review_date', None)
        
        # å¯¹æ¯ä¸ªæ–¹é¢åˆ›å»ºä¸€è¡Œ
        for aspect in aspects:
            score_col = f"{aspect}_score"
            count_col = f"{aspect}_count"
            
            if score_col in row and not pd.isna(row[score_col]):
                aspect_data_list.append({
                    'review_id': review_id,
                    'product_id': product_id,
                    'aspect': aspect,
                    'score': row[score_col],
                    'count': row.get(count_col, 0),
                    'rating': rating,
                    'brand': brand,
                    'price_range': price_range,
                    'review_date': review_date
                })
    
    aspect_data = pd.DataFrame(aspect_data_list)
    
    # 2. å“ç‰Œç»´åº¦è¡¨
    if 'brand' in df.columns:
        brands = df['brand'].unique()
        brand_data = pd.DataFrame({
            'brand': brands,
            'review_count': [len(df[df['brand'] == b]) for b in brands]
        })
        
        # è®¡ç®—æ¯ä¸ªå“ç‰Œçš„å¹³å‡è¯„åˆ†
        brand_data['avg_rating'] = [df[df['brand'] == b]['rating'].mean() for b in brands]
        
        # æ·»åŠ æ¯ä¸ªå“ç‰Œçš„æœ€é«˜è¯„åˆ†æ–¹é¢
        brand_best_aspects = []
        for brand in brands:
            brand_df = df[df['brand'] == brand]
            best_aspect = ''
            best_score = 0
            for aspect in aspects:
                score_col = f"{aspect}_score"
                if score_col in df.columns:
                    avg_score = brand_df[score_col].mean()
                    if avg_score > best_score:
                        best_score = avg_score
                        best_aspect = aspect
            brand_best_aspects.append({
                'brand': brand,
                'best_aspect': best_aspect,
                'best_aspect_score': best_score
            })
        brand_best_aspects_df = pd.DataFrame(brand_best_aspects)
        brand_data = pd.merge(brand_data, brand_best_aspects_df, on='brand', how='left')
    else:
        brand_data = pd.DataFrame(columns=['brand', 'review_count', 'avg_rating'])
    
    # 3. ä»·æ ¼åŒºé—´ç»´åº¦è¡¨
    if 'price_range' in df.columns:
        price_ranges = df['price_range'].unique()
        price_data = pd.DataFrame({
            'price_range': price_ranges,
            'review_count': [len(df[df['price_range'] == p]) for p in price_ranges]
        })
        
        # è®¡ç®—æ¯ä¸ªä»·æ ¼åŒºé—´çš„å¹³å‡è¯„åˆ†
        price_data['avg_rating'] = [df[df['price_range'] == p]['rating'].mean() for p in price_ranges]
    else:
        price_data = pd.DataFrame(columns=['price_range', 'review_count', 'avg_rating'])
    
    # 4. æ–¹é¢ç»´åº¦è¡¨
    aspect_info = []
    for aspect in aspects:
        score_col = f"{aspect}_score"
        if score_col in df.columns:
            avg_score = df[score_col].dropna().mean()
            count = df[score_col].count()
            aspect_info.append({
                'aspect': aspect,
                'aspect_name': aspect.replace('_', ' ').title(),
                'avg_score': avg_score,
                'count': count
            })
    aspect_dim = pd.DataFrame(aspect_info)
    
    # 5. æ—¶é—´ç»´åº¦è¡¨(å¦‚æœæœ‰æ—¥æœŸæ•°æ®)
    if 'review_date' in df.columns and 'review_date' in aspect_data.columns:
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
        try:
            aspect_data['review_date'] = pd.to_datetime(aspect_data['review_date'])
            aspect_data['year'] = aspect_data['review_date'].dt.year
            aspect_data['month'] = aspect_data['review_date'].dt.month
            aspect_data['quarter'] = aspect_data['review_date'].dt.quarter
            aspect_data['year_month'] = aspect_data['review_date'].dt.strftime('%Y-%m')
        except:
            print("æ— æ³•å¤„ç†æ—¥æœŸæ•°æ®ï¼Œè·³è¿‡æ—¶é—´ç»´åº¦è¡¨åˆ›å»º")
    
    # ä¿å­˜æ•°æ®æ–‡ä»¶
    main_path = os.path.join(output_path, 'main_data.csv')
    aspect_path = os.path.join(output_path, 'aspect_data.csv')
    brand_path = os.path.join(output_path, 'brand_data.csv')
    price_path = os.path.join(output_path, 'price_data.csv')
    aspect_dim_path = os.path.join(output_path, 'aspect_dim.csv')
    
    main_data.to_csv(main_path, index=False)
    aspect_data.to_csv(aspect_path, index=False)
    brand_data.to_csv(brand_path, index=False)
    price_data.to_csv(price_path, index=False)
    aspect_dim.to_csv(aspect_dim_path, index=False)
    
    print(f"æ•°æ®å·²æˆåŠŸå¯¼å‡ºè‡³ {output_path} ç›®å½•")
    
    # åŒæ—¶å¯¼å‡ºä¸€ä¸ªæ•´åˆçš„Excelæ–‡ä»¶ï¼Œæ–¹ä¾¿ç›´æ¥å¯¼å…¥PowerBI
    excel_path = os.path.join(output_path, 'powerbi_data.xlsx')
    
    # åœ¨å¯¼å‡ºåˆ°Excelå‰æ¸…ç†æ•°æ®
    clean_main_data = clean_for_excel(main_data)
    clean_aspect_data = clean_for_excel(aspect_data)
    clean_brand_data = clean_for_excel(brand_data)
    clean_price_data = clean_for_excel(price_data)
    clean_aspect_dim = clean_for_excel(aspect_dim)
    
    try:
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            clean_main_data.to_excel(writer, sheet_name='ä¸»æ•°æ®', index=False)
            clean_aspect_data.to_excel(writer, sheet_name='æ–¹é¢è¯„åˆ†æ•°æ®', index=False)
            clean_brand_data.to_excel(writer, sheet_name='å“ç‰Œæ•°æ®', index=False)
            clean_price_data.to_excel(writer, sheet_name='ä»·æ ¼åŒºé—´æ•°æ®', index=False)
            clean_aspect_dim.to_excel(writer, sheet_name='æ–¹é¢ç»´åº¦', index=False)
        
        print(f"æ•´åˆçš„Excelæ–‡ä»¶å·²ä¿å­˜è‡³ {excel_path}")
    except Exception as e:
        print(f"å¯¼å‡ºExcelæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        print("ä½†CSVæ–‡ä»¶å·²æˆåŠŸå¯¼å‡ºï¼Œæ‚¨å¯ä»¥ç›´æ¥å°†CSVæ–‡ä»¶å¯¼å…¥PowerBI")
    
    return {
        'main_data': main_path,
        'aspect_data': aspect_path,
        'brand_data': brand_path,
        'price_data': price_path,
        'aspect_dim': aspect_dim_path,
        'excel_file': excel_path if os.path.exists(excel_path) else None
    }
```

## main.py

```python
import os
import pandas as pd
import argparse
from src.data.acquisition import get_audio_dataset
from src.data.preprocessing import get_processed_dataset
from src.features.aspect_extraction import create_review_aspects_dataset
from src.visualization.plots import create_all_visualizations
from src.utils.export import prepare_powerbi_data

def main(args):
    """
    ä¸»ç¨‹åºå‡½æ•°ï¼Œè¿è¡Œå®Œæ•´åˆ†ææµç¨‹
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        None
    """
    print("å¼€å§‹éŸ³é¢‘è¯„è®ºåˆ†æé¡¹ç›®...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs('data/raw', exist_ok=True)
    os.makedirs('data/processed', exist_ok=True)
    os.makedirs('outputs/figures', exist_ok=True)
    os.makedirs('outputs/powerbi_data', exist_ok=True)
    
    # æ§åˆ¶æ‰§è¡Œçš„æ­¥éª¤
    do_data_collection = args.all or args.data_collection
    do_preprocessing = args.all or args.preprocessing
    do_aspect_analysis = args.all or args.aspect_analysis
    do_visualization = args.all or args.visualization
    
    # 1. æ•°æ®è·å–
    raw_data = None
    if do_data_collection:
        print("\n=== æ­¥éª¤ 1: æ•°æ®è·å– ===")
        raw_data = get_audio_dataset(
            url=args.data_url,
            save_dir='data/raw',
            processed_dir='data/processed'
        )
    
    # 2. æ•°æ®é¢„å¤„ç†
    processed_data = None
    if do_preprocessing:
        print("\n=== æ­¥éª¤ 2: æ•°æ®é¢„å¤„ç† ===")
        # å¦‚æœå‰ä¸€æ­¥æ²¡æœ‰åŠ è½½æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        if raw_data is None:
            try:
                raw_data = pd.read_csv('data/processed/audio_reviews.csv')
                print("ä»æ–‡ä»¶åŠ è½½åŸå§‹æ•°æ®ã€‚")
            except FileNotFoundError:
                print("æœªæ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ --data-collection æ­¥éª¤ã€‚")
                return
        
        processed_data = get_processed_dataset(
            raw_df=raw_data,
            save_path='data/processed/processed_audio_reviews.csv'
        )
    
    # 3. æ–¹é¢åˆ†æ
    aspect_data = None
    if do_aspect_analysis:
        print("\n=== æ­¥éª¤ 3: æ–¹é¢åˆ†æ ===")
        # å¦‚æœå‰ä¸€æ­¥æ²¡æœ‰åŠ è½½æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        if processed_data is None:
            try:
                processed_data = pd.read_csv('data/processed/processed_audio_reviews.csv')
                print("ä»æ–‡ä»¶åŠ è½½é¢„å¤„ç†æ•°æ®ã€‚")
            except FileNotFoundError:
                print("æœªæ‰¾åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ --preprocessing æ­¥éª¤ã€‚")
                return
        
        aspect_data = create_review_aspects_dataset(
            df=processed_data,
            output_path='data/processed/review_aspects.csv'
        )
    
    # 4. å¯è§†åŒ–
    if do_visualization:
        print("\n=== æ­¥éª¤ 4: å¯è§†åŒ– ===")
        # å¦‚æœå‰ä¸€æ­¥æ²¡æœ‰åŠ è½½æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        if aspect_data is None:
            try:
                aspect_data = pd.read_csv('data/processed/review_aspects.csv')
                print("ä»æ–‡ä»¶åŠ è½½æ–¹é¢åˆ†ææ•°æ®ã€‚")
            except FileNotFoundError:
                print("æœªæ‰¾åˆ°æ–¹é¢åˆ†ææ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ --aspect-analysis æ­¥éª¤ã€‚")
                return
        
        create_all_visualizations(
            df=aspect_data,
            output_dir='outputs/figures'
        )
    
    # 5. å¯¼å‡ºPowerBIæ•°æ®ï¼ˆå¯é€‰ï¼‰
    if args.export_powerbi:
        print("\n=== æ­¥éª¤ 5: å¯¼å‡ºPowerBIæ•°æ® ===")
        # å¦‚æœå‰ä¸€æ­¥æ²¡æœ‰åŠ è½½æ•°æ®ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        if aspect_data is None:
            try:
                aspect_data = pd.read_csv('data/processed/review_aspects.csv')
                print("ä»æ–‡ä»¶åŠ è½½æ–¹é¢åˆ†ææ•°æ®ã€‚")
            except FileNotFoundError:
                print("æœªæ‰¾åˆ°æ–¹é¢åˆ†ææ•°æ®æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ --aspect-analysis æ­¥éª¤ã€‚")
                return
        
        # å¯¼å‡ºæ•°æ®ä»¥ä¾¿åœ¨PowerBIä¸­ä½¿ç”¨
        prepare_powerbi_data(
            df=aspect_data,
            output_path='outputs/powerbi_data'
        )
    
    print("\néŸ³é¢‘è¯„è®ºåˆ†æé¡¹ç›®æˆåŠŸå®Œæˆï¼")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æ')
    
    parser.add_argument('--all', action='store_true', 
                        help='è¿è¡Œæ‰€æœ‰æ­¥éª¤')
    parser.add_argument('--data-collection', action='store_true', 
                        help='è¿è¡Œæ•°æ®è·å–æ­¥éª¤')
    parser.add_argument('--preprocessing', action='store_true', 
                        help='è¿è¡Œé¢„å¤„ç†æ­¥éª¤')
    parser.add_argument('--aspect-analysis', action='store_true', 
                        help='è¿è¡Œæ–¹é¢åˆ†ææ­¥éª¤')
    parser.add_argument('--visualization', action='store_true', 
                        help='è¿è¡Œå¯è§†åŒ–æ­¥éª¤')
    parser.add_argument('--export-powerbi', action='store_true', 
                        help='å¯¼å‡ºæ•°æ®ç”¨äºPowerBIå¯è§†åŒ–')
    parser.add_argument('--data-url', type=str, 
                        default="http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz",
                        help='æ•°æ®é›†URL')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ­¥éª¤ï¼Œé»˜è®¤è¿è¡Œæ‰€æœ‰æ­¥éª¤
    if not any([args.all, args.data_collection, args.preprocessing, 
                args.aspect_analysis, args.visualization, args.export_powerbi]):
        args.all = True
    
    main(args)
```

## dashboard.py

```python
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from wordcloud import WordCloud
import os
import sys

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æä»ªè¡¨ç›˜",
    page_icon="ğŸ§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åº”ç”¨æ ‡é¢˜å’Œä»‹ç»
st.title("ğŸ§ éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æä»ªè¡¨ç›˜")
st.markdown("""
è¿™ä¸ªä»ªè¡¨ç›˜å±•ç¤ºäº†ä»Amazonè¯„è®ºä¸­æå–çš„éŸ³é¢‘è®¾å¤‡è¯„ä»·åˆ†æï¼ŒåŒ…æ‹¬å„æ–¹é¢è¯„åˆ†ã€å“ç‰Œæ¯”è¾ƒå’Œä»·æ ¼åŒºé—´åˆ†æã€‚
""")

# ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
@st.cache_data
def load_data():
    """åŠ è½½ä¸»æ•°æ®é›†å’Œæ–¹é¢æ•°æ®"""
    try:
        df = pd.read_csv('data/processed/review_aspects.csv')
        aspect_data = pd.read_csv('outputs/powerbi_data/aspect_data.csv')
        brand_data = pd.read_csv('outputs/powerbi_data/brand_data.csv')
        price_data = pd.read_csv('outputs/powerbi_data/price_data.csv')
        aspect_dim = pd.read_csv('outputs/powerbi_data/aspect_dim.csv')
        return df, aspect_data, brand_data, price_data, aspect_dim
    except FileNotFoundError:
        st.error("æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®å¤„ç†æ­¥éª¤ã€‚")
        if not os.path.exists('data/processed/review_aspects.csv'):
            st.info("å°è¯•è¿è¡Œ `python main.py --all` ç”Ÿæˆæ‰€éœ€æ•°æ®æ–‡ä»¶")
        return None, None, None, None, None

# åŠ è½½æ•°æ®
df, aspect_data, brand_data, price_data, aspect_dim = load_data()

# æ£€æŸ¥æ•°æ®æ˜¯å¦æˆåŠŸåŠ è½½
if df is None:
    st.stop()

# ä¾§è¾¹æ  - ç­›é€‰å™¨
st.sidebar.header("æ•°æ®ç­›é€‰")

# å“ç‰Œç­›é€‰
all_brands = sorted(df['brand'].unique().tolist())
selected_brands = st.sidebar.multiselect(
    "é€‰æ‹©å“ç‰Œ", 
    options=all_brands,
    default=all_brands[:5] if len(all_brands) > 5 else all_brands
)

# ä»·æ ¼åŒºé—´ç­›é€‰
all_price_ranges = sorted(df['price_range'].unique().tolist())
selected_price_ranges = st.sidebar.multiselect(
    "é€‰æ‹©ä»·æ ¼åŒºé—´", 
    options=all_price_ranges,
    default=all_price_ranges
)

# è¯„åˆ†èŒƒå›´ç­›é€‰
min_rating, max_rating = st.sidebar.slider(
    "è¯„åˆ†èŒƒå›´", 
    min_value=1.0, 
    max_value=5.0,
    value=(1.0, 5.0),
    step=0.5
)

# ç­›é€‰æ•°æ®
filtered_df = df.copy()
if selected_brands:
    filtered_df = filtered_df[filtered_df['brand'].isin(selected_brands)]
if selected_price_ranges:
    filtered_df = filtered_df[filtered_df['price_range'].isin(selected_price_ranges)]
filtered_df = filtered_df[(filtered_df['rating'] >= min_rating) & (filtered_df['rating'] <= max_rating)]

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs(["æ€»ä½“æ¦‚è§ˆ", "æ–¹é¢åˆ†æ", "å“ç‰Œæ¯”è¾ƒ", "ä»·æ ¼åŒºé—´åˆ†æ"])

with tab1:
    st.header("æ€»ä½“æ¦‚è§ˆ")
    
    # è¡Œ1: å…³é”®æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("è¯„è®ºæ€»æ•°", len(filtered_df))
    with col2:
        st.metric("å¹³å‡è¯„åˆ†", f"{filtered_df['rating'].mean():.2f}")
    with col3:
        st.metric("å“ç‰Œæ•°é‡", len(filtered_df['brand'].unique()))
    with col4:
        st.metric("ä»·æ ¼åŒºé—´æ•°é‡", len(filtered_df['price_range'].unique()))
    
    # è¡Œ2: è¯„åˆ†åˆ†å¸ƒå’Œè¯äº‘
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("è¯„åˆ†åˆ†å¸ƒ")
        rating_counts = filtered_df['rating'].value_counts().sort_index()
        fig = px.bar(
            x=rating_counts.index, 
            y=rating_counts.values,
            labels={'x': 'è¯„åˆ†', 'y': 'æ•°é‡'},
            title='è¯„åˆ†åˆ†å¸ƒ',
            color=rating_counts.index,
            color_continuous_scale='Viridis'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("è¯„è®ºå­—æ•°åˆ†å¸ƒ")
        fig = px.histogram(
            filtered_df, 
            x="word_count",
            nbins=50,
            labels={'word_count': 'å­—æ•°', 'count': 'è¯„è®ºæ•°é‡'},
            title='è¯„è®ºå­—æ•°åˆ†å¸ƒ'
        )
        fig.update_layout(bargap=0.1)
        st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("æ–¹é¢åˆ†æ")
    
    # è·å–æ–¹é¢è¯„åˆ†åˆ—
    aspect_cols = [col for col in filtered_df.columns if col.endswith('_score')]
    aspects = [col.replace('_score', '') for col in aspect_cols]
    
    # ç¿»è¯‘æ–¹é¢åç§°ä¸ºä¸­æ–‡
    aspect_translation = {
        'sound_quality': 'éŸ³è´¨',
        'comfort': 'èˆ’é€‚åº¦',
        'battery': 'ç”µæ± ',
        'connectivity': 'è¿æ¥æ€§',
        'noise_cancellation': 'é™å™ª',
        'build_quality': 'åšå·¥',
        'controls': 'æ§åˆ¶',
        'price': 'ä»·æ ¼',
        'microphone': 'éº¦å…‹é£',
        'design': 'è®¾è®¡'
    }
    
    # è¡Œ1: æ–¹é¢é€‰æ‹©
    selected_aspect = st.selectbox(
        "é€‰æ‹©è¦è¯¦ç»†åˆ†æçš„æ–¹é¢",
        options=aspects,
        format_func=lambda x: aspect_translation.get(x, x)
    )
    
    # è¡Œ2: æ–¹é¢è¯„åˆ†é›·è¾¾å›¾å’Œè¯¦ç»†åˆ†æ
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("å„æ–¹é¢å¹³å‡è¯„åˆ†")
        # è®¡ç®—æ¯ä¸ªæ–¹é¢çš„å¹³å‡å¾—åˆ†
        aspect_means = {}
        for aspect, aspect_col in zip(aspects, aspect_cols):
            aspect_means[aspect] = filtered_df[aspect_col].mean()
        
        # æ’åºå¹¶æ•´ç†æ•°æ®
        aspect_means = {k: v for k, v in sorted(aspect_means.items(), key=lambda item: item[1], reverse=True)}
        
        # é›·è¾¾å›¾æ•°æ®
        categories = [aspect_translation.get(k, k) for k in aspect_means.keys()]
        values = list(aspect_means.values())
        values = [0 if np.isnan(v) else v for v in values]
        
        # åˆ›å»ºé›·è¾¾å›¾
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name='å¹³å‡åˆ†æ•°'
        ))
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 10]
                )
            ),
            title="éŸ³é¢‘è®¾å¤‡å„æ–¹é¢è¯„åˆ†"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader(f"{aspect_translation.get(selected_aspect, selected_aspect)}è¯¦ç»†åˆ†æ")
        score_col = f"{selected_aspect}_score"
        
        # è¯„åˆ†åˆ†å¸ƒ
        fig = px.histogram(
            filtered_df[filtered_df[score_col].notna()], 
            x=score_col,
            nbins=20,
            labels={score_col: 'è¯„åˆ†', 'count': 'æ•°é‡'},
            title=f'{aspect_translation.get(selected_aspect, selected_aspect)}è¯„åˆ†åˆ†å¸ƒ'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # å¹³å‡è¯„åˆ†
        avg_score = filtered_df[score_col].mean()
        st.metric(f"{aspect_translation.get(selected_aspect, selected_aspect)}å¹³å‡è¯„åˆ†", f"{avg_score:.2f}/10")

with tab3:
    st.header("å“ç‰Œæ¯”è¾ƒ")
    
    # è·å–è¯„è®ºæ•°é‡è¶³å¤Ÿçš„å“ç‰Œ
    brand_review_counts = filtered_df['brand'].value_counts()
    min_reviews = st.slider("æœ€å°‘è¯„è®ºæ•°é‡", min_value=5, max_value=100, value=30)
    valid_brands = brand_review_counts[brand_review_counts >= min_reviews].index.tolist()
    
    if not valid_brands:
        st.warning(f"æ²¡æœ‰å“ç‰Œçš„è¯„è®ºæ•°é‡è‡³å°‘ä¸º {min_reviews}ã€‚è¯·é™ä½æœ€å°‘è¯„è®ºæ•°é‡é˜ˆå€¼ã€‚")
    else:
        # æœ€å¤šæ˜¾ç¤º10ä¸ªå“ç‰Œ
        valid_brands = valid_brands[:10]
        
        # ä¸ºæ¯ä¸ªå“ç‰Œè®¡ç®—å¹³å‡æ–¹é¢è¯„åˆ†
        brand_data = []
        
        for brand in valid_brands:
            brand_df = filtered_df[filtered_df['brand'] == brand]
            
            # è®¡ç®—è¿™ä¸ªå“ç‰Œçš„æ–¹é¢å¹³å‡åˆ†
            for aspect in aspects:
                score_col = f"{aspect}_score"
                avg_score = brand_df[score_col].mean()
                if not np.isnan(avg_score):
                    brand_data.append({
                        'Brand': brand,
                        'Aspect': aspect_translation.get(aspect, aspect),
                        'Score': avg_score
                    })
        
        # åˆ›å»ºæ•°æ®æ¡†
        brand_scores_df = pd.DataFrame(brand_data)
        
        if len(brand_scores_df) > 0:
            # åˆ›å»ºçƒ­åŠ›å›¾
            heatmap_data = brand_scores_df.pivot(index='Brand', columns='Aspect', values='Score')
            fig = px.imshow(
                heatmap_data,
                labels=dict(x="æ–¹é¢", y="å“ç‰Œ", color="åˆ†æ•°"),
                x=heatmap_data.columns,
                y=heatmap_data.index,
                aspect="auto",
                color_continuous_scale='Viridis',
                range_color=[1, 10],
                title='å“ç‰Œæ–¹é¢è¯„åˆ†æ¯”è¾ƒ'
            )
            fig.update_layout(height=600)
            st.plotly_chart(fig, use_container_width=True)
            
            # å“ç‰Œæ€»ä½“è¯„åˆ†æ¡å½¢å›¾
            st.subheader("å“ç‰Œæ€»ä½“è¯„åˆ†")
            brand_overall = heatmap_data.mean(axis=1).sort_values(ascending=False)
            fig = px.bar(
                x=brand_overall.index,
                y=brand_overall.values,
                labels={'x': 'å“ç‰Œ', 'y': 'å¹³å‡è¯„åˆ†'},
                color=brand_overall.values,
                color_continuous_scale='Viridis',
                range_color=[1, 10]
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå“ç‰Œæ¯”è¾ƒã€‚")

with tab4:
    st.header("ä»·æ ¼åŒºé—´åˆ†æ")
    
    # ä¸ºæ¯ä¸ªä»·æ ¼åŒºé—´è®¡ç®—æ–¹é¢è¯„åˆ†
    price_range_data = []
    
    for price_range in selected_price_ranges:
        price_df = filtered_df[filtered_df['price_range'] == price_range]
        
        if len(price_df) < 10:  # è·³è¿‡æ ·æœ¬å¤ªå°‘çš„ä»·æ ¼åŒºé—´
            continue
            
        # è®¡ç®—è¿™ä¸ªä»·æ ¼åŒºé—´çš„æ–¹é¢å¹³å‡åˆ†
        for aspect in aspects:
            score_col = f"{aspect}_score"
            avg_score = price_df[score_col].mean()
            if not np.isnan(avg_score):
                price_range_data.append({
                    'Price Range': price_range,
                    'Aspect': aspect_translation.get(aspect, aspect),
                    'Score': avg_score
                })
    
    # åˆ›å»ºæ•°æ®æ¡†
    price_scores_df = pd.DataFrame(price_range_data)
    
    if len(price_scores_df) > 0:
        # åˆ›å»ºçƒ­åŠ›å›¾
        heatmap_data = price_scores_df.pivot(index='Price Range', columns='Aspect', values='Score')
        fig = px.imshow(
            heatmap_data,
            labels=dict(x="æ–¹é¢", y="ä»·æ ¼åŒºé—´", color="åˆ†æ•°"),
            x=heatmap_data.columns,
            y=heatmap_data.index,
            aspect="auto",
            color_continuous_scale='Viridis',
            range_color=[1, 10],
            title='ä»·æ ¼åŒºé—´æ–¹é¢è¯„åˆ†æ¯”è¾ƒ'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ä»·æ ¼åŒºé—´æŠ˜çº¿å›¾
        st.subheader("ä¸åŒä»·æ ¼åŒºé—´å„æ–¹é¢å¾—åˆ†æ¯”è¾ƒ")
        fig = go.Figure()
        
        for aspect in heatmap_data.columns:
            fig.add_trace(go.Scatter(
                x=heatmap_data.index,
                y=heatmap_data[aspect],
                mode='lines+markers',
                name=aspect
            ))
        
        fig.update_layout(
            xaxis_title="ä»·æ ¼åŒºé—´",
            yaxis_title="å¹³å‡åˆ†æ•° (1-10)",
            yaxis=dict(range=[0, 10])
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ä»·å€¼æ¯”(æ€§ä»·æ¯”)åˆ†æ
        st.subheader("æ€§ä»·æ¯”åˆ†æ")
        
        # ç®€å•å®šä¹‰æ€§ä»·æ¯” = éŸ³è´¨å¾—åˆ† / ç›¸å¯¹ä»·æ ¼æŒ‡æ•°
        price_value_map = {
            'é¢„ç®—å‹(<$50)': 1,
            'ä¸­ç«¯($50-$150)': 2,
            'é«˜ç«¯($150-$300)': 3,
            'è±ªåå‹(>$300)': 4
        }
        
        if 'éŸ³è´¨' in heatmap_data.columns and all(pr in price_value_map for pr in heatmap_data.index):
            value_data = []
            for pr in heatmap_data.index:
                score = heatmap_data.loc[pr, 'éŸ³è´¨']
                price_index = price_value_map.get(pr, 1)
                value_ratio = score / price_index
                value_data.append({
                    'Price Range': pr,
                    'Sound Quality': score,
                    'Value Ratio': value_ratio
                })
            
            value_df = pd.DataFrame(value_data)
            fig = px.bar(
                value_df,
                x='Price Range',
                y='Value Ratio',
                color='Sound Quality',
                labels={'Value Ratio': 'æ€§ä»·æ¯”æŒ‡æ•°', 'Price Range': 'ä»·æ ¼åŒºé—´'},
                title='éŸ³è´¨æ€§ä»·æ¯”åˆ†æ',
                color_continuous_scale='Viridis'
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œä»·æ ¼åŒºé—´åˆ†æã€‚")

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("Â© 2025 éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿ | ä½¿ç”¨Streamlitåˆ›å»º")
```

## requirements.txt

```
pandas>=1.3.0
numpy>=1.20.0
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.3.0
nltk>=3.6.0
spacy>=3.1.0
scikit-learn>=1.0.0
wordcloud>=1.8.0
tqdm>=4.60.0
requests>=2.25.0
openpyxl>=3.0.0
streamlit>=1.8.0
```

## æ–‡ä»¶ç»“æ„åˆ›å»ºè„šæœ¬ (setup.sh)

```bash
#!/bin/bash

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
echo "åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„..."
mkdir -p data/raw data/processed
mkdir -p outputs/figures outputs/powerbi_data
mkdir -p src/data src/features src/visualization src/utils

# åˆ›å»ºç©ºçš„__init__.pyæ–‡ä»¶
touch src/__init__.py
touch src/data/__init__.py
touch src/features/__init__.py
touch src/visualization/__init__.py
touch src/utils/__init__.py

# å®‰è£…ä¾èµ–
echo "å®‰è£…é¡¹ç›®ä¾èµ–..."
pip install -r requirements.txt

# ä¸‹è½½NLTKèµ„æº
echo "ä¸‹è½½NLTKèµ„æº..."
python -c "import nltk; nltk.download('punkt'); nltk.download('vader_lexicon'); nltk.download('stopwords')"

# ä¸‹è½½spaCyæ¨¡å‹
echo "ä¸‹è½½spaCyæ¨¡å‹..."
python -m spacy download en_core_web_sm

echo "é¡¹ç›®ç¯å¢ƒå·²å‡†å¤‡å°±ç»ªï¼"
echo "è¿è¡Œ 'python main.py --all' å¼€å§‹æ•°æ®åˆ†ææµç¨‹"
echo "è¿è¡Œ 'streamlit run dashboard.py' å¯åŠ¨äº¤äº’å¼ä»ªè¡¨ç›˜"
```

## ä½¿ç”¨æŒ‡å—

### å®‰è£…ä¸è®¾ç½®

1. **å®‰è£…ä¾èµ–**:
```bash
pip install -r requirements.txt
python -m nltk.downloader punkt vader_lexicon stopwords
python -m spacy download en_core_web_sm
```

2. **åˆ›å»ºç›®å½•ç»“æ„**:
```bash
chmod +x setup.sh
./setup.sh
```

### è¿è¡Œåˆ†æ

```bash
# è¿è¡Œæ‰€æœ‰æ­¥éª¤
python main.py --all

# åˆ†æ­¥éª¤è¿è¡Œ
python main.py --data-collection  # è·å–æ•°æ®
python main.py --preprocessing     # æ•°æ®é¢„å¤„ç†
python main.py --aspect-analysis   # æ–¹é¢åˆ†æ
python main.py --visualization     # å¯è§†åŒ–
python main.py --export-powerbi    # å¯¼å‡ºæ•°æ®

# å¯åŠ¨Streamlitä»ªè¡¨ç›˜
streamlit run dashboard.py
```

ä»¥ä¸Šæ˜¯å®Œæ•´çš„éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿä»£ç ï¼ŒåŒ…æ‹¬äº†æ‰€æœ‰æ¨¡å—ã€PowerBIæ•°æ®å¯¼å‡ºåŠŸèƒ½å’Œæ–°æ·»åŠ çš„Streamlitä»ªè¡¨ç›˜ã€‚è¯·æ ¹æ®éœ€è¦è‡ªè¡Œè°ƒæ•´å‚æ•°å’Œé…ç½®ã€‚
## ğŸ“Š æ•°æ®åˆ†ææ–¹æ³•

### æ–‡æœ¬åˆ†ææµç¨‹

1. **æ–‡æœ¬é¢„å¤„ç†**
   - è½¬ä¸ºå°å†™
   - ç§»é™¤URLå’Œç‰¹æ®Šå­—ç¬¦
   - åˆ†è¯
   - ç§»é™¤åœç”¨è¯

2. ## æ–¹æ³•è®º - æ–¹é¢æå– (Aspect Extraction)

æœ¬é¡¹ç›®æ ¸å¿ƒçš„æ–¹é¢æå–åŠŸèƒ½æ—¨åœ¨ä»ç”¨æˆ·è¯„è®ºä¸­è¯†åˆ«å‡ºè®¨è®ºçš„äº§å“ç‰¹æ€§ï¼ˆæ–¹é¢ï¼‰ï¼Œå¹¶å°†è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ä¸ä¹‹å…³è”ã€‚

### å½“å‰å®ç°æ–¹æ³•

å½“å‰ç‰ˆæœ¬é‡‡ç”¨äº†ä¸€ç§åŸºäº **é¢„å®šä¹‰å…³é”®è¯åŒ¹é…** çš„æ–¹æ³•ï¼Œç»“åˆ **è¯„è®ºæ•´ä½“è¯„åˆ†** ä½œä¸ºæƒ…æ„Ÿä»£ç†ã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

1.  **é¢„å®šä¹‰æ–¹é¢ä¸å…³é”®è¯:** åœ¨ `config.py` æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬é¢„å…ˆå®šä¹‰äº†ä¸€ç»„å¸¸è§çš„éŸ³é¢‘äº§å“æ–¹é¢ï¼ˆå¦‚ "Sound Quality", "Battery Life", "Comfort" ç­‰ï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸ªæ–¹é¢å…³è”äº†ä¸€ç³»åˆ—ç›¸å…³çš„å…³é”®è¯åˆ—è¡¨ã€‚
2.  **æ–‡æœ¬é¢„å¤„ç†:** è¯„è®ºæ–‡æœ¬ç»è¿‡åŸºç¡€é¢„å¤„ç†ï¼ŒåŒ…æ‹¬è½¬ä¸ºå°å†™ã€å»é™¤æ ‡ç‚¹ç¬¦å·ç­‰ï¼ˆè¯¦è§ `src/data/preprocessing.py`ï¼‰ã€‚
3.  **å…³é”®è¯åŒ¹é…:** ç³»ç»Ÿéå†æ¯ä¸€æ¡é¢„å¤„ç†åçš„è¯„è®ºæ–‡æœ¬ã€‚å¯¹äº `config.py` ä¸­å®šä¹‰çš„æ¯ä¸€ä¸ªæ–¹é¢ï¼Œç³»ç»Ÿæ£€æŸ¥è¯„è®ºæ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«è¯¥æ–¹é¢å¯¹åº”çš„**ä»»ä½•ä¸€ä¸ªå…³é”®è¯**ï¼ˆå½“å‰å®ç°ä¸ºå­å­—ç¬¦ä¸²åŒ¹é…ï¼‰ã€‚
4.  **æ–¹é¢è¯†åˆ«:** å¦‚æœè¯„è®ºæ–‡æœ¬ä¸­æ‰¾åˆ°äº†æŸä¸€æ–¹é¢çš„ä¸€ä¸ªæˆ–å¤šä¸ªå…³é”®è¯ï¼Œåˆ™è®¤ä¸ºè¯¥è¯„è®ºæåŠäº†è¯¥æ–¹é¢ã€‚
5.  **æƒ…æ„Ÿ/è¯„åˆ†å…³è”:** **å…³é”®å‡è®¾ï¼š** å½“å‰æ–¹æ³•å°†è¯¥æ¡è¯„è®ºçš„**æ•´ä½“è¯„åˆ† (rating)** ç›´æ¥ä½œä¸ºå…¶æ‰€æåŠçš„æ‰€æœ‰æ–¹é¢çš„æƒ…æ„Ÿå¾—åˆ†ã€‚ä¾‹å¦‚ï¼Œä¸€æ¡è¯„åˆ†ä¸º 5 æ˜Ÿä¸”æåŠäº† "sound" å’Œ "comfort" çš„è¯„è®ºï¼Œä¼šè¢«è®°å½•ä¸º "Sound Quality" å¾—åˆ† 5ï¼Œ"Comfort" å¾—åˆ† 5ã€‚

### æ–¹æ³•çš„ä¼˜ç‚¹

* **å®ç°ç®€å•:** è¯¥æ–¹æ³•é€»è¾‘æ¸…æ™°ï¼Œä»£ç å®ç°ç›¸å¯¹ç›´æ¥ã€‚
* **è®¡ç®—å¿«é€Ÿ:** çº¯æ–‡æœ¬åŒ¹é…æ“ä½œï¼Œå¯¹äºä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†å¤„ç†é€Ÿåº¦è¾ƒå¿«ã€‚
* **å¯è§£é‡Šæ€§å¼º:** æå–å‡ºçš„æ–¹é¢ç›´æ¥åŸºäºæ˜ç¡®çš„å…³é”®è¯ï¼Œæ˜“äºç†è§£ä¸ºä½•æŸæ¡è¯„è®ºè¢«å½’ç±»åˆ°ç‰¹å®šæ–¹é¢ã€‚
* **æ˜“äºå®šåˆ¶:** é€šè¿‡ä¿®æ”¹ `config.py` ä¸­çš„å…³é”®è¯åˆ—è¡¨ï¼Œå¯ä»¥æ–¹ä¾¿åœ°è°ƒæ•´æˆ–æ‰©å±•è¦†ç›–çš„æ–¹é¢ã€‚

### æ–¹æ³•çš„å±€é™æ€§ä¸æŒ‘æˆ˜

å°½ç®¡è¯¥æ–¹æ³•åœ¨å½“å‰é˜¶æ®µæœ‰æ•ˆï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›æ˜æ˜¾çš„å±€é™æ€§ï¼š

* **ä¸Šä¸‹æ–‡ç†è§£ä¸è¶³:** æ— æ³•ç†è§£è¯è¯­çš„å®é™…å«ä¹‰å’Œä¸Šä¸‹æ–‡ã€‚ä¾‹å¦‚ï¼Œæ— æ³•åŒºåˆ† "good sound" å’Œ "no sound"ã€‚
* **å¿½ç•¥å¦å®šè¯å’Œä¿®é¥°è¯:** ç®€å•çš„å…³é”®è¯åŒ¹é…ä¸èƒ½å¤„ç†å¦å®šæƒ…å†µï¼ˆå¦‚ "not comfortable" å¯èƒ½ä¼šå› ä¸ºåŒ¹é…åˆ° "comfortable" è€Œè¢«é”™è¯¯è¯†åˆ«ï¼‰æˆ–ç¨‹åº¦å‰¯è¯ï¼ˆå¦‚ "very loud" å’Œ "slightly loud"ï¼‰ã€‚
* **æƒ…æ„Ÿå…³è”ç²—ç³™:** ä½¿ç”¨è¯„è®ºçš„æ•´ä½“è¯„åˆ†ä½œä¸ºæ¯ä¸ªæ–¹é¢çš„æƒ…æ„Ÿä»£ç†æ˜¯ä¸€ä¸ª**å¼ºå‡è®¾**ã€‚ä¸€æ¡è¯„è®ºå¯èƒ½åŒæ—¶ç§°èµéŸ³è´¨ï¼ˆæ­£é¢ï¼‰ä½†æŠ±æ€¨ç”µæ± ç»­èˆªï¼ˆè´Ÿé¢ï¼‰ï¼Œæ•´ä½“è¯„åˆ†å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ å¯¹å•ä¸ªæ–¹é¢çš„æƒ…æ„Ÿã€‚
* **å…³é”®è¯ä¾èµ–:** æ•ˆæœé«˜åº¦ä¾èµ–äº `config.py` ä¸­å…³é”®è¯åˆ—è¡¨çš„**è´¨é‡å’Œå®Œå¤‡æ€§**ã€‚æœªåŒ…å«çš„å…³é”®è¯æˆ–æ–°çš„è¡¨è¾¾æ–¹å¼å°†æ— æ³•è¢«è¯†åˆ«ã€‚
* **å¤šæ–¹é¢æƒ…æ„Ÿæ··æ·†:** éš¾ä»¥åŒºåˆ†è¯„è®ºä¸­é’ˆå¯¹ä¸åŒæ–¹é¢çš„ä¸åŒæƒ…æ„Ÿè¡¨è¾¾ã€‚

### æœªæ¥å·¥ä½œä¸æ½œåœ¨æ”¹è¿›æ–¹å‘

ä¸ºäº†å…‹æœå½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œæœªæ¥å¯ä»¥æ¢ç´¢ä»¥ä¸‹æ”¹è¿›æ–¹å‘ï¼š

1.  **æ”¹è¿›å…³é”®è¯åŒ¹é…:**
    * ä½¿ç”¨**å…¨è¯åŒ¹é…**ï¼ˆä¾‹å¦‚æ­£åˆ™è¡¨è¾¾å¼ `\bkeyword\b`ï¼‰é¿å…éƒ¨åˆ†åŒ¹é…å¸¦æ¥çš„æ­§ä¹‰ã€‚
    * ç»“åˆ**è¯å½¢è¿˜åŸ (Lemmatization)** æˆ– **è¯å¹²æå– (Stemming)** å°†ä¸åŒå½¢æ€çš„è¯ï¼ˆå¦‚ "connect", "connecting", "connection"ï¼‰å½’ä¸€åŒ–ã€‚
2.  **å¼•å…¥è§„åˆ™å’Œæƒ…æ„Ÿè¯å…¸:**
    * åœ¨å…³é”®è¯é™„è¿‘æŸ¥æ‰¾**æƒ…æ„Ÿè¯**ï¼ˆå¦‚ "good", "bad", "amazing", "terrible"ï¼‰ã€‚
    * è€ƒè™‘æƒ…æ„Ÿè¯å‰çš„**å¦å®šè¯**ï¼ˆ"not good"ï¼‰å’Œ**ç¨‹åº¦å‰¯è¯**ï¼ˆ"very good"ï¼‰æ¥è°ƒæ•´æƒ…æ„Ÿè¯„åˆ†ã€‚å¯ä»¥ä½¿ç”¨ç°æœ‰çš„æƒ…æ„Ÿè¯å…¸åº“ï¼ˆå¦‚ VADER, SentiWordNetï¼‰ã€‚
3.  **åŸºäºä¾èµ–å…³ç³»è§£æ:**
    * ä½¿ç”¨ `spaCy` ç­‰åº“è¿›è¡Œ**ä¾å­˜å¥æ³•åˆ†æ**ï¼Œæ‰¾å‡ºä¸æ–¹é¢å…³é”®è¯ç›´æ¥ç›¸å…³çš„è¯„ä»·æ€§è¯è¯­ï¼Œå»ºç«‹æ›´å‡†ç¡®çš„æ–¹é¢-æƒ…æ„Ÿé“¾æ¥ã€‚
4.  **æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ æ–¹æ³•:**
    * **æ–¹é¢æœ¯è¯­æŠ½å– (ATE):** ä½¿ç”¨åºåˆ—æ ‡æ³¨æ¨¡å‹ï¼ˆå¦‚ BiLSTM-CRF, BERTï¼‰è‡ªåŠ¨ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºæ–¹é¢è¯è¯­ï¼Œå‡å°‘å¯¹é¢„å®šä¹‰å…³é”®è¯çš„ä¾èµ–ã€‚
    * **æ–¹é¢æƒ…æ„Ÿåˆ†ç±» (ASC):** å¯¹äºå·²è¯†åˆ«å‡ºçš„æ–¹é¢è¯ï¼Œä½¿ç”¨åˆ†ç±»æ¨¡å‹ï¼ˆå¦‚ BERT-based classifiersï¼‰åˆ¤æ–­å…¶åœ¨è¯¥ä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“æƒ…æ„Ÿææ€§ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰å’Œå¼ºåº¦ã€‚è¿™å¯ä»¥è§£å†³æ•´ä½“è¯„åˆ†å¸¦æ¥çš„é—®é¢˜ã€‚
    * **ç«¯åˆ°ç«¯ ABSA:** ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹åŒæ—¶å®Œæˆæ–¹é¢æŠ½å–å’Œæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ã€‚


3. **æƒ…æ„Ÿåˆ†æ**
   - ä½¿ç”¨NLTKçš„VADERæƒ…æ„Ÿåˆ†æå™¨
   - è®¡ç®—æ¯ä¸ªæ–¹é¢ç›¸å…³å¥å­çš„æƒ…æ„Ÿå¾—åˆ†
   - è§„èŒƒåŒ–å¾—åˆ†åˆ°1-10èŒƒå›´

4. **å“ç‰Œè¯†åˆ«**
   - ä»è¯„è®ºæ–‡æœ¬ä¸­æå–å¸¸è§éŸ³é¢‘è®¾å¤‡å“ç‰Œ
   - æ”¯æŒé€šè¿‡å¤–éƒ¨æ˜ å°„æä¾›äº§å“IDåˆ°å“ç‰Œçš„æ˜ å°„

5. **ä»·æ ¼åŒºé—´åˆ†ç±»**
   - æ”¯æŒå®é™…ä»·æ ¼æ•°æ®
   - åœ¨æ— å®é™…ä»·æ ¼æ•°æ®æ—¶ä½¿ç”¨å“ˆå¸Œå€¼æ¨¡æ‹Ÿä»·æ ¼åˆ†å¸ƒ

## ğŸ“ˆ å¯è§†åŒ–ç»“æœ

ç³»ç»Ÿç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–ï¼š

1. **è¯„åˆ†åˆ†å¸ƒ**ï¼šå±•ç¤ºè¯„åˆ†é¢‘ç‡åˆ†å¸ƒ
2. **æ–¹é¢è¯„åˆ†é›·è¾¾å›¾**ï¼šç›´è§‚æ˜¾ç¤ºå„æ–¹é¢çš„å¹³å‡å¾—åˆ†
3. **å“ç‰Œæ¯”è¾ƒçƒ­åŠ›å›¾**ï¼šæ¯”è¾ƒä¸åŒå“ç‰Œåœ¨å„æ–¹é¢çš„è¡¨ç°
4. **ä»·æ ¼åŒºé—´æ¯”è¾ƒ**ï¼šåˆ†æä¸åŒä»·æ ¼åŒºé—´äº§å“çš„æ€§ä»·æ¯”
5. **é«˜ä½è¯„åˆ†è¯äº‘**ï¼šå±•ç¤ºé«˜è¯„åˆ†å’Œä½è¯„åˆ†è¯„è®ºä¸­çš„å…³é”®è¯

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å‘½ä»¤è¡Œå‚æ•°

```bash
# è¿è¡Œæ‰€æœ‰æ­¥éª¤
python main.py --all

# åˆ†æ­¥éª¤è¿è¡Œ
python main.py --data-collection  # è·å–æ•°æ®
python main.py --preprocessing     # æ•°æ®é¢„å¤„ç†
python main.py --aspect-analysis   # æ–¹é¢åˆ†æ
python main.py --visualization     # å¯è§†åŒ–
python main.py --export-powerbi    # å¯¼å‡ºPowerBIæ•°æ®

# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æº
python main.py --data-url "http://your-data-source.com/dataset.json.gz"
```

### è‡ªå®šä¹‰åˆ†æ

è¦è‡ªå®šä¹‰åˆ†æï¼Œå¯ä»¥ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°ï¼š

- åœ¨`AUDIO_KEYWORDS`ä¸­æ·»åŠ æˆ–åˆ é™¤å…³é”®è¯ä»¥æ›´æ”¹éŸ³é¢‘è®¾å¤‡ç­›é€‰æ¡ä»¶
- åœ¨`ASPECT_CONFIG`ä¸­ä¿®æ”¹æ–¹é¢å®šä¹‰åŠå…¶å…³é”®è¯
- åœ¨`VIZ_CONFIG`ä¸­è°ƒæ•´å¯è§†åŒ–å‚æ•°

## ğŸ”§ æ‰©å±•ä¸ä¼˜åŒ–

### æ½œåœ¨æ”¹è¿›æ–¹å‘

1. **æ›´é«˜çº§çš„æ–¹é¢æå–**ï¼š
   - ä½¿ç”¨ä¾å­˜å¥æ³•åˆ†ææé«˜æ–¹é¢è¯†åˆ«å‡†ç¡®æ€§
   - å®ç°åŸºäºBERTæˆ–å…¶ä»–é¢„è®­ç»ƒæ¨¡å‹çš„æ–¹é¢æå–

2. **æ›´ç»†ç²’åº¦çš„æƒ…æ„Ÿåˆ†æ**ï¼š
   - åŒºåˆ†æ–¹é¢ç‰¹å®šçš„æƒ…æ„Ÿææ€§
   - è¯†åˆ«è¯„è®ºä¸­çš„æ¯”è¾ƒå’Œå¯¹æ¯”è¡¨è¾¾

3. **æ•´åˆå¤–éƒ¨æ•°æ®**ï¼š
   - æ·»åŠ äº§å“è§„æ ¼æ•°æ®
   - æ·»åŠ æ—¶é—´åºåˆ—åˆ†æï¼Œè·Ÿè¸ªäº§å“è¯„ä»·éšæ—¶é—´å˜åŒ–

4. **äº¤äº’å¼å¯è§†åŒ–**ï¼š
   - å¼€å‘åŸºäºWebçš„äº¤äº’å¼ä»ªè¡¨æ¿
   - æ”¯æŒå®æ—¶æ•°æ®æ›´æ–°å’Œç­›é€‰

## ğŸ“š å‚è€ƒèµ„æ–™ä¸æ•°æ®æ¥æº

- æ•°æ®é›†ï¼šAmazonç”µå­äº§å“è¯„è®ºæ•°æ®é›†
- è‡ªç„¶è¯­è¨€å¤„ç†åº“ï¼šNLTKã€spaCy
- å¯è§†åŒ–åº“ï¼šMatplotlibã€Seabornã€Plotly

## ğŸ§  æŠ€æœ¯åŸç†

### æ–¹é¢æå–ä¸æƒ…æ„Ÿåˆ†æ

æœ¬é¡¹ç›®ä½¿ç”¨åŸºäºå…³é”®è¯çš„æ–¹æ³•ä»è¯„è®ºä¸­æå–æ–¹é¢ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨VADERæƒ…æ„Ÿåˆ†æå™¨è®¡ç®—æƒ…æ„Ÿå¾—åˆ†ã€‚VADERæ˜¯ä¸€ä¸ªåŸºäºè§„åˆ™çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼Œä¸“ä¸ºç¤¾äº¤åª’ä½“æ–‡æœ¬è®¾è®¡ï¼Œèƒ½å¤Ÿå¤„ç†ä¿šè¯­ã€è¡¨æƒ…ç¬¦å·å’Œå¸¸è§ç¼©å†™ã€‚

### è§„èŒƒåŒ–å¾—åˆ†è®¡ç®—

ä¸ºäº†å°†æƒ…æ„Ÿå¾—åˆ†è½¬æ¢ä¸ºç›´è§‚çš„1-10è¯„åˆ†å°ºåº¦ï¼Œç³»ç»Ÿä½¿ç”¨ä»¥ä¸‹è½¬æ¢å…¬å¼ï¼š

```
normalized_score = ((raw_sentiment_score + 1) / 2) * 9 + 1
```

è¿™å°†åŸå§‹çš„-1åˆ°1çš„æƒ…æ„Ÿå¾—åˆ†æ˜ å°„åˆ°1-10çš„èŒƒå›´å†…ã€‚

## ç»“è¯­

éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿæ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œå–„çš„æ•°æ®åˆ†æå·¥å…·ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•åº”ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ä»éç»“æ„åŒ–æ–‡æœ¬æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„è§è§£ã€‚é€šè¿‡å¯¹ç”¨æˆ·è¯„è®ºçš„æ·±å…¥åˆ†æï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå¸®åŠ©éŸ³é¢‘è®¾å¤‡åˆ¶é€ å•†ã€è¥é”€äººå‘˜å’Œæ¶ˆè´¹è€…æ›´å¥½åœ°äº†è§£äº§å“çš„ä¼˜ç¼ºç‚¹ï¼ŒæŒ‡å¯¼äº§å“æ”¹è¿›å’Œè´­ä¹°å†³ç­–ã€‚

éŸ³é¢‘è®¾å¤‡è¯„è®ºåˆ†æç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚ä¿®æ”¹é…ç½®å‚æ•°ï¼Œæ·»åŠ æ–°çš„åˆ†æç»´åº¦ï¼Œæˆ–è€…é›†æˆå…¶ä»–æ•°æ®æºï¼Œä»¥æ»¡è¶³ç‰¹å®šçš„åˆ†æéœ€æ±‚ã€‚